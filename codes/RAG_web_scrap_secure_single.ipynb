{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2643936",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 valid links. Scraping the content...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "206d2983297346088bddb584b4fb8082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scraping items:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f0d46f99a2246ae81a26d3dd60e9eef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Partitioning text:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total partition count: 5\n",
      "Models embedding dimension: 3072\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7819f39b12774c84b279a355e6a70d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embedding partitions:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import faiss\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from urllib.parse import urljoin\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "ollama_url_inf = \"http://localhost:11434/api/show\"\n",
    "ollama_url_emb = \"http://localhost:11434/api/embeddings\"\n",
    "ollama_url_gen = \"http://localhost:11434/api/generate\"\n",
    "ollama_model_name = \"llama3.2:latest\"\n",
    "\n",
    "base_url = 'https://en.wikipedia.org/wiki/Bangladesh'\n",
    "\n",
    "# Configure Selenium Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--disable-gpu')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "service = Service()\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "def get_visitable_links(base_url):\n",
    "    driver.get(base_url)\n",
    "    time.sleep(1)\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    links = []\n",
    "    for a_tag in soup.find_all('a', href=True):\n",
    "        full_url = urljoin(base_url, a_tag['href'])\n",
    "        if '#' not in full_url and '%' not in full_url and full_url.startswith(base_url) and full_url not in links:\n",
    "            links.append(full_url)\n",
    "    return links\n",
    "\n",
    "def scrape_text_from_url(url):\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    text_content = ' '.join([p.get_text() for p in soup.find_all('p')])\n",
    "    text_content = ' '.join(text_content.split())\n",
    "    return text_content\n",
    "\n",
    "def partition_text(text, max_length):\n",
    "    sentences = text.split('. ')\n",
    "    partitions = []\n",
    "    current_part = []\n",
    "    current_length = 0\n",
    "    \n",
    "    for sentence in tqdm(sentences, desc=\"Partitioning text\"):\n",
    "        current_length += len(sentence.split())\n",
    "        current_part.append(sentence)\n",
    "        \n",
    "        if current_length > max_length:\n",
    "            partitions.append('. '.join(current_part))\n",
    "            current_part = []\n",
    "            current_length = 0\n",
    "\n",
    "    if current_part:\n",
    "        partitions.append('. '.join(current_part))\n",
    "\n",
    "    return partitions\n",
    "\n",
    "\n",
    "def get_embedding_shape():\n",
    "    payload = { \"model\": ollama_model_name }\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    response = requests.post(ollama_url_inf, headers=headers, data=json.dumps(payload))\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        # Check if 'model_info' and 'embedding_length' exist in the response\n",
    "        if 'model_info' in result and 'llama.embedding_length' in result['model_info']:\n",
    "            embedding_length = result['model_info'][\"llama.embedding_length\"]\n",
    "            return embedding_length\n",
    "        else:\n",
    "            print(\"Embedding length not found in the model info.\")\n",
    "            return 0\n",
    "    else:\n",
    "        print(f\"Error from Ollama: {response.status_code}\")\n",
    "        return 0\n",
    "\n",
    "def get_embedding(text):\n",
    "    payload = { \"model\": ollama_model_name, \"prompt\": text}\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    response = requests.post(ollama_url_emb, headers=headers, data=json.dumps(payload))\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        embedding = np.array(result['embedding'])\n",
    "        return embedding\n",
    "    else:\n",
    "        print(f\"Error from Ollama: {response.status_code}\")\n",
    "        return np.zeros(768)  # (adjust dimension based on model)\n",
    "\n",
    "def store_in_faiss(partitions):\n",
    "    dimension = get_embedding_shape()\n",
    "    print(f\"Models embedding dimension: {dimension}\")\n",
    "    index = faiss.IndexFlatL2(dimension)  # L2 distance\n",
    "\n",
    "    doc_vectors = []\n",
    "    doc_ids = []\n",
    "    \n",
    "    for i, partition in tqdm(enumerate(partitions), total=len(partitions), desc=\"Embedding partitions\"):\n",
    "        embedding = get_embedding(partition)\n",
    "        index.add(np.array([embedding]))\n",
    "        doc_vectors.append(embedding)\n",
    "        doc_ids.append(i)\n",
    "    \n",
    "    return index, doc_ids\n",
    "\n",
    "def retrieve_with_rag(query, faiss_index, doc_ids, k=2):\n",
    "    query_embedding = get_embedding(query)\n",
    "    distances, indices = faiss_index.search(np.array([query_embedding]), k=k)  # Retrieve top-1 closest documents\n",
    "    retrieved_docs = []\n",
    "    for i in indices[0]:\n",
    "        if i >= len(partitions):\n",
    "            print(f\"WARN: Index {i} out of bounds for partition list.\")\n",
    "            continue\n",
    "        doc_id = doc_ids[i]\n",
    "        retrieved_docs.append(partitions[doc_id])\n",
    "    combined_docs = \"\\n\".join(retrieved_docs)\n",
    "    rag_prompt = f\"Context:\\n{combined_docs}\\n\\nQuery: {query}\\nAnswer:\"\n",
    "    payload = {\"model\": ollama_model_name, \"prompt\": rag_prompt, \"stream\": False}\n",
    "    response = requests.post(ollama_url_gen, headers={\"Content-Type\": \"application/json\"}, \n",
    "                             data=json.dumps(payload))\n",
    "    return response.json()\n",
    "\n",
    "valid_links = get_visitable_links(base_url)[1:4]\n",
    "print(f\"Found {len(valid_links)} valid links. Scraping the content...\")\n",
    "\n",
    "all_text = \"\"\n",
    "for link in tqdm(valid_links, desc=\"Scraping items\"):\n",
    "    text_content = scrape_text_from_url(link)\n",
    "    all_text += text_content + \"\\n\\n\"\n",
    "\n",
    "partitions = partition_text(all_text, max_length=512)\n",
    "print(f'Total partition count: {len(partitions)}')\n",
    "\n",
    "# Store the partitions in FAISS\n",
    "faiss_index, doc_ids = store_in_faiss(partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acf96b50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Where is Bangladesh located? \n",
      "\n",
      "RAG Response:\n",
      "Bangladesh is a country in South Asia, centered on the transnational historical region of Bengal along the eponymous bay.\n"
     ]
    }
   ],
   "source": [
    "query = \"Where is Bangladesh located?\"\n",
    "rag_response = retrieve_with_rag(query, faiss_index, doc_ids)\n",
    "answer = rag_response[\"response\"]\n",
    "print(f\"Query: {query} \\n\\nRAG Response:\\n{answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6d278d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Who is the father of Bangladesh? \n",
      "\n",
      "RAG Response:\n",
      "The text does not mention who is considered the \"father\" of Bangladesh. It does provide information about the country's history, culture, and demographics, but it does not include any specific information about a person being referred to as the \"father\" of Bangladesh.\n"
     ]
    }
   ],
   "source": [
    "query = \"Who is the father of Bangladesh?\"\n",
    "rag_response = retrieve_with_rag(query, faiss_index, doc_ids)\n",
    "answer = rag_response[\"response\"]\n",
    "print(f\"Query: {query} \\n\\nRAG Response:\\n{answer}\")\n",
    "\n",
    "# Close the Selenium browser\n",
    "#driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
