{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hissain/mlworks/blob/main/codes/RNN_CBOW_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "kH3NgfTuJJXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Constant definition\n",
        "RANDOM_SEED = 1\n",
        "CONTEXT_SIZE = 3\n",
        "EMBEDDING_DIM = 10"
      ],
      "metadata": {
        "id": "ydRlAUfNJYAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(RANDOM_SEED)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPHTsGZiVE5y",
        "outputId": "c42d9d0f-8d7d-4b19-d6dd-cedfdcd35fb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7da3602a5730>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# word level tokenization\n",
        "class Tokenizer:\n",
        "    def __init__(self):\n",
        "        self.mapping = {}\n",
        "        self.reverse_mapping = {}\n",
        "\n",
        "    def encode(self, text):\n",
        "        words = text.split()\n",
        "        tokens = []\n",
        "        for word in words:\n",
        "            if word not in self.mapping:\n",
        "                mapped_int = len(self.mapping)\n",
        "                self.mapping[word] = mapped_int\n",
        "                self.reverse_mapping[mapped_int] = word\n",
        "            tokens.append(self.mapping[word])\n",
        "        return tokens\n",
        "\n",
        "    def decode(self, tokens):\n",
        "        words = [self.reverse_mapping[token] for token in tokens]\n",
        "        return \" \".join(words)\n"
      ],
      "metadata": {
        "id": "KixNPnOqJs4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()"
      ],
      "metadata": {
        "id": "rDEtkR14g7Fn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Taking a random paragraph\n",
        "text = \"We are living in an AI era . One day AI will take all the Human jobs .\""
      ],
      "metadata": {
        "id": "mV-GVqEohGcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating dataset\n",
        "dataset = []\n",
        "tokens = tokenizer.encode(text)\n",
        "for i in range(len(tokens) - CONTEXT_SIZE):\n",
        "    dataset.append((tokens[i:i + CONTEXT_SIZE], tokens[i + CONTEXT_SIZE]))"
      ],
      "metadata": {
        "id": "4Y4vNjoGJvX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.mapping)\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpXbcKGPg9ch",
        "outputId": "a57cc651-50c8-446b-cc24-ab975041c6d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Used for tokenization purpose\n",
        "def get_one_hot(tokens):\n",
        "    return F.one_hot(\n",
        "        torch.tensor(tokens),\n",
        "        num_classes=vocab_size\n",
        "    ).flatten().type(torch.float)"
      ],
      "metadata": {
        "id": "FOTiazubYQXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CBOW model\n",
        "class CBOW(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, context_size):\n",
        "    super(CBOW, self).__init__()\n",
        "    self.hidden = nn.Linear(vocab_size * context_size, embedding_dim)\n",
        "    self.output = nn.Linear(embedding_dim, vocab_size)\n",
        "\n",
        "  def forward(self, input):\n",
        "    return self.output(self.hidden(get_one_hot(input)))"
      ],
      "metadata": {
        "id": "cGjResgcYqKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "model = CBOW(vocab_size, EMBEDDING_DIM, CONTEXT_SIZE)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "QLNEtvRZYr2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rb79f-I4-ZJ1",
        "outputId": "d3a27311-296a-4193-95bc-6bf8db03a527"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "for epoch in range(100):\n",
        "    total_loss = 0\n",
        "    for input, label in dataset:\n",
        "        predictions = model(input)\n",
        "        loss = loss_function(predictions, get_one_hot(label))\n",
        "        total_loss += loss\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(total_loss.item())\n"
      ],
      "metadata": {
        "id": "sRpSJfJTYtMc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "733afb0e-e335-4aab-badc-14fc9f9f9819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41.66307067871094\n",
            "41.2083854675293\n",
            "40.83362579345703\n",
            "40.46225357055664\n",
            "40.088836669921875\n",
            "39.71091842651367\n",
            "39.32661056518555\n",
            "38.93415069580078\n",
            "38.53190612792969\n",
            "38.11841583251953\n",
            "37.69240951538086\n",
            "37.252830505371094\n",
            "36.798851013183594\n",
            "36.329830169677734\n",
            "35.84531784057617\n",
            "35.34503936767578\n",
            "34.8288459777832\n",
            "34.2967529296875\n",
            "33.74892807006836\n",
            "33.1856803894043\n",
            "32.607444763183594\n",
            "32.0147590637207\n",
            "31.408281326293945\n",
            "30.788738250732422\n",
            "30.15692710876465\n",
            "29.513708114624023\n",
            "28.859996795654297\n",
            "28.1967716217041\n",
            "27.525053024291992\n",
            "26.845914840698242\n",
            "26.16048812866211\n",
            "25.4699649810791\n",
            "24.775575637817383\n",
            "24.07860565185547\n",
            "23.380393981933594\n",
            "22.68229866027832\n",
            "21.985736846923828\n",
            "21.2921085357666\n",
            "20.60283088684082\n",
            "19.9193058013916\n",
            "19.242895126342773\n",
            "18.57492446899414\n",
            "17.916641235351562\n",
            "17.26922035217285\n",
            "16.63374137878418\n",
            "16.011194229125977\n",
            "15.40245246887207\n",
            "14.808279991149902\n",
            "14.229336738586426\n",
            "13.66616439819336\n",
            "13.119206428527832\n",
            "12.5888032913208\n",
            "12.07519817352295\n",
            "11.5785551071167\n",
            "11.098942756652832\n",
            "10.636371612548828\n",
            "10.190773963928223\n",
            "9.762027740478516\n",
            "9.349944114685059\n",
            "8.954296112060547\n",
            "8.57480239868164\n",
            "8.211145401000977\n",
            "7.862966060638428\n",
            "7.529881954193115\n",
            "7.211475849151611\n",
            "6.907312393188477\n",
            "6.616933345794678\n",
            "6.339868068695068\n",
            "6.075639724731445\n",
            "5.823759078979492\n",
            "5.583737850189209\n",
            "5.355086803436279\n",
            "5.137320041656494\n",
            "4.929958820343018\n",
            "4.732529163360596\n",
            "4.544572830200195\n",
            "4.365640163421631\n",
            "4.195294380187988\n",
            "4.033115386962891\n",
            "3.8786966800689697\n",
            "3.7316462993621826\n",
            "3.5915913581848145\n",
            "3.4581716060638428\n",
            "3.331045150756836\n",
            "3.209885597229004\n",
            "3.0943806171417236\n",
            "2.9842348098754883\n",
            "2.879168748855591\n",
            "2.778914213180542\n",
            "2.6832194328308105\n",
            "2.5918467044830322\n",
            "2.504565954208374\n",
            "2.421166181564331\n",
            "2.341444253921509\n",
            "2.2652087211608887\n",
            "2.19227933883667\n",
            "2.1224849224090576\n",
            "2.055664300918579\n",
            "1.9916657209396362\n",
            "1.9303462505340576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "input_text = \"One day AI\"\n",
        "correct_output = \"will\"\n",
        "\n",
        "with torch.no_grad():\n",
        "    prediction = model(tokenizer.encode(input_text))\n",
        "    print(torch.argmax(prediction).item())\n",
        "    print(tokenizer.reverse_mapping[torch.argmax(prediction).item()])"
      ],
      "metadata": {
        "id": "zy3ZKHI5JhMI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "add9d564-eeb2-449f-d0d3-7f7e2624329c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "will\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding of a word\n",
        "token = tokenizer.mapping[\"will\"]\n",
        "print(model.output.weight[token])"
      ],
      "metadata": {
        "id": "TI9fW5PadvqQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93f773da-b99f-4773-fc79-f9e757d40af2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.6185,  0.7577,  0.4743,  0.5531, -0.6016,  0.5008,  0.0481, -0.6179,\n",
            "         0.3598,  0.2874], grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cdqcKIMaZy7g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}