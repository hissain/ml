{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "91808bb3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hissain/myenv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf6eeee6361b4454be2d34be75834c9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83e899a2b9e24739a31481e61d182836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13f81205c97c47f0b3492065852d97c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38d7ac8e770e4cd1b78c77372792c8e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c9646384752416cae4c30695ad92a01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7f34aa009324b2a859f8937ca5a7510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 9 URLs from pickle file\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71acc594bb2f49f4b43a97dc0dd3768d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scraping pages:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Chunks: 770\n",
      "Chunk: Contents List of wars by death toll Table (List of wars by death toll): | 0 ||| Part of a series on || War (outline) || showHistory || showMilitary || showBattlespace || showWeapons || showTactics || showOperational || showStrategy || showGrand strategy || showAdministrative || showOrganization || showPersonnel || showLogistics || showScience || showLaw || showTheory || showNon-warfare || showCulture || showRelated || hideLists Battles Military occupations Military terms Operations Sieges War crimes Wars Weapons Writers || vte ||\n",
      "Source URL: https://en.wikipedia.org/wiki/List_of_wars_by_death_toll\n",
      "\n",
      "Chunk: This list of wars by death toll includes all deaths that are either directly or indirectly caused by war. These numbers include the deaths of military personnel which are the direct results of a battle or other military wartime actions, as well as wartime / war - related deaths of civilians which are often results of war - induced epidemics, famines, genocide, etc. Due to incomplete records, the destruction of evidence, differing methods of counting, and various other reasons, death tolls of wars have often been quite uncertain, and heavily debated. While the definition of war isn't entirely clear - cut, there is a general understanding of what it is. Merriam - Webster defines war as \" a state of usually open and declared armed hostile conflict between states or nations \", Oxford English Dictionary defines war as \" hostile contention by means of armed forces, carried on between nations, states, or rulers, or between parties in the same nation or state ; the employment of armed forces against a foreign power, or against an opposing party in the state \", and Encyclop√¶dia Britannica defines war as \" a conflict between political groups involving hostilities of considerable duration and magnitude \".\n",
      "Source URL: https://en.wikipedia.org/wiki/List_of_wars_by_death_toll\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from io import StringIO\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "#model_path = '/Users/hissain/git/github/models/all-MiniLM-L6-v2'\n",
    "model_path = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, force_download=True)\n",
    "\n",
    "# Define maximum token length per chunk\n",
    "max_token_length = 250\n",
    "\n",
    "def clean(text):\n",
    "    clean_text = re.sub(r'\\[\\s*\\d+\\s*\\]', '', text)\n",
    "    return clean_text\n",
    "\n",
    "def get_text_content(element):\n",
    "    return ' '.join(str(e) for e in element.stripped_strings)\n",
    "\n",
    "def chunk_text(text, max_token_length):\n",
    "    tokens = tokenizer.encode(text, add_special_tokens=False)\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(tokens):\n",
    "        end = min(start + max_token_length, len(tokens))\n",
    "        chunk = tokenizer.decode(tokens[start:end])\n",
    "        chunks.append(chunk)\n",
    "        start = end\n",
    "    return chunks\n",
    "\n",
    "def merge_small_chunks(chunks, max_token_length):\n",
    "    merged_chunks = []\n",
    "    temp_chunk = \"\"\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        if len(tokenizer.encode(temp_chunk + \" \" + chunk, add_special_tokens=False)) <= max_token_length:\n",
    "            temp_chunk += \" \" + chunk\n",
    "        else:\n",
    "            while len(tokenizer.encode(temp_chunk, add_special_tokens=False)) > max_token_length:\n",
    "                split_point = max_token_length - 1\n",
    "                merged_chunks.append(tokenizer.decode(tokenizer.encode(temp_chunk, add_special_tokens=False)[:split_point]))\n",
    "                temp_chunk = tokenizer.decode(tokenizer.encode(temp_chunk, add_special_tokens=False)[split_point:])\n",
    "                \n",
    "            merged_chunks.append(temp_chunk.strip())\n",
    "            temp_chunk = chunk\n",
    "    \n",
    "    if temp_chunk:\n",
    "        merged_chunks.append(temp_chunk.strip())\n",
    "    \n",
    "    return merged_chunks\n",
    "\n",
    "def chunk_table(df, max_token_length, header_info):\n",
    "    table_chunks = []\n",
    "    current_chunk = header_info + ' ||| '\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        row_text = ' | '.join([str(cell) for cell in row if pd.notna(cell)])\n",
    "        row_text = clean(row_text)\n",
    "        combined_text = current_chunk + row_text + ' || '\n",
    "        \n",
    "        if len(tokenizer.encode(combined_text)) <= max_token_length:\n",
    "            current_chunk += row_text + ' || '\n",
    "        else:\n",
    "            row_chunks = chunk_text(row_text, max_token_length)\n",
    "            for sub_chunk in row_chunks:\n",
    "                if len(tokenizer.encode(current_chunk)) + len(tokenizer.encode(sub_chunk)) <= max_token_length:\n",
    "                    current_chunk += sub_chunk + ' || '\n",
    "                else:\n",
    "                    table_chunks.append(current_chunk.strip())\n",
    "                    current_chunk = header_info + ' ||| ' + sub_chunk + ' || '\n",
    "                    \n",
    "    if current_chunk:\n",
    "        table_chunks.append(current_chunk.strip())\n",
    "    \n",
    "    return table_chunks\n",
    "\n",
    "\n",
    "def scrape_and_chunk_page(content):\n",
    "\n",
    "    soup = BeautifulSoup(content[1], 'html.parser') # index-1 for html\n",
    "    \n",
    "    chunks = []\n",
    "    current_url = content[0] #index-0 for url\n",
    "    last_header = \"\"\n",
    "\n",
    "    elements = soup.find_all(['h1', 'h2', 'h3', 'h4', 'p', 'table'])\n",
    "    for element in elements:\n",
    "        if element.name in ['h1', 'h2', 'h3', 'h4']:\n",
    "            header_text = get_text_content(element)\n",
    "            header_text = clean(header_text)\n",
    "            last_header = \"\\nTable (\" + header_text + \"):\"\n",
    "            header_chunks = chunk_text(header_text, max_token_length)\n",
    "            chunks.extend([(chunk, current_url) for chunk in header_chunks])\n",
    "            \n",
    "        elif element.name == 'p':\n",
    "            paragraph_text = get_text_content(element)\n",
    "            paragraph_text = clean(paragraph_text)\n",
    "            paragraph_chunks = chunk_text(paragraph_text, max_token_length)\n",
    "            chunks.extend([(chunk, current_url) for chunk in paragraph_chunks])\n",
    "            \n",
    "        elif element.name == 'table':\n",
    "            table_html = StringIO(str(element))\n",
    "            df = pd.read_html(table_html)[0]\n",
    "            \n",
    "            if df.empty:\n",
    "                continue\n",
    "            \n",
    "            df.dropna(axis=0, how='all', inplace=True)\n",
    "            df.dropna(axis=1, how='all', inplace=True)\n",
    "            \n",
    "            df.columns = [str(col) for col in df.columns]\n",
    "            header_info = last_header + ' | ' + ' | '.join(df.columns) if not df.columns.empty else last_header\n",
    "            \n",
    "            table_chunks = chunk_table(df, max_token_length, header_info)\n",
    "            chunks.extend([(chunk, current_url) for chunk in table_chunks])\n",
    "\n",
    "    text_chunks = [chunk[0] for chunk in chunks]\n",
    "    final_chunks = merge_small_chunks(text_chunks, max_token_length)\n",
    "    \n",
    "    return [(chunk, current_url) for chunk in final_chunks]\n",
    "\n",
    "def scrape_and_chunk(html_contents):\n",
    "    chunks = []\n",
    "    for content in tqdm(html_contents, desc=\"Scraping pages\"):\n",
    "        chunks.extend(scrape_and_chunk_page(content))\n",
    "    return chunks\n",
    "\n",
    "with open(\"html_contents.pkl\", \"rb\") as f:\n",
    "    html_contents = pickle.load(f)\n",
    "\n",
    "print(f\"Loaded {len(html_contents)} URLs from pickle file\")\n",
    "scraped_chunks = scrape_and_chunk(html_contents)\n",
    "\n",
    "print(f\"Total Chunks: {len(scraped_chunks)}\")\n",
    "\n",
    "for chunk, url in scraped_chunks[:2]:\n",
    "    print(f\"Chunk: {chunk}\\nSource URL: {url}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "54ad5af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mark', 'Today', 'Sunday']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def ne(text):\n",
    "    doc = nlp(text)\n",
    "    entities = [(ent.text) for ent in doc.ents]\n",
    "    return entities\n",
    "\n",
    "ne(\"Hello Mr. Mark! Today is Sunday!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ba8c6e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_chunks = [chunk for chunk in scraped_chunks if len(chunk[0]) > 350]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "627e1394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ed83f83a1f34e928c71c6a6fff2050c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting NEs:   0%|          | 0/741 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ne_chunks = []\n",
    "for chunk in tqdm(scraped_chunks, desc=\"Extracting NEs\"):\n",
    "    ne_chunks.append((chunk[0], chunk[1], \", \".join(ne(chunk[0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d0bb509a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Table (1700‚Äì1799): | ('Start', 'Start') | ('Finish', 'Finish') | ('Name of Conflict', 'Name of Conflict') | ('Belligerents', 'Victorious party (if applicable)') | ('Belligerents', 'Defeated party (if applicable)') ||| 1707 | 1707 | Mughal war of succession ( 1707 ) | Faction of Bahadur Shah I | Faction of Muhammad Azam Shah Faction of Muhammad Kam Bakhsh || 1707 | 1708 | Bulavin Rebellion | Russia | Peasants || 1707 | 1709 | War of the Emboabas | Kingdom of Portugal  Portuguese settlers  Early Brazilian settlers | Bandeirantes Paulistas || 1708 | 1708 | Kanzhal War (1708)\\xa0[de] | Kabardia | Crimean Khanate  Ottoman Empire || 1708 | 1709 | Comacchio War\\xa0[de] | Austria | Papal States || 1709 | 1722 | Hotaki‚ÄìSafavid War | Hotak dynasty | Safavid dynasty ||\",\n",
       " 'https://en.wikipedia.org/wiki/List_of_wars:_1500%E2%80%931799',\n",
       " \"1700‚Äì1799, Start', 'Start', Finish', 'Finish', Name of Conflict', Name of Conflict', Defeated, 1707 | 1707, 1707, Muhammad Azam Shah Faction, Muhammad Kam Bakhsh, Bulavin Rebellion, Russia, Peasants, 1707 | 1709, Emboabas, Kingdom, Portugal, Portuguese, Early Brazilian, Bandeirantes, 1708, 1708, Kanzhal War, 1708, Kabardia, Crimean Khanate  , 1708 | 1709, Comacchio War, Austria, Papal States, 1709 | 1722, Hotaki‚ÄìSafavid War, Safavid\")"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ne_chunks[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8f543279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ceccffe97634bf1bfa780d7484b245e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0824f53a0c2d41f4817287c6258ba599",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Storing to Qdrant:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 741 relevant chunks\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'e' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[125], line 190\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStored \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(scraped_chunks)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m relevant chunks\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m#except Exception as e:\u001b[39;00m\n\u001b[0;32m--> 190\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError storing in Qdrant: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43me\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'e' is not defined"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from collections import Counter\n",
    "import re\n",
    "import numpy as np\n",
    "from qdrant_client import QdrantClient, models\n",
    "from tqdm.notebook import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from IPython.display import display, clear_output, Markdown\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "# Load SpaCy's English model for Named Entity Recognition\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "session = requests.Session()\n",
    "retry = Retry(total=5, backoff_factor=1, status_forcelist=[429, 500, 502, 503, 504])\n",
    "adapter = HTTPAdapter(max_retries=retry)\n",
    "session.mount(\"http://\", adapter)\n",
    "session.headers.update({\"Connection\": \"keep-alive\", \"Content-Type\": \"application/json\"})\n",
    "\n",
    "qdrant_url = \"http://localhost:6333\"\n",
    "collection_name = \"wiki_collection\"\n",
    "ollama_url_gen = \"http://localhost:11434/api/generate\"\n",
    "ollama_model_name = \"llama3.2:latest\"\n",
    "\n",
    "client = QdrantClient(url=qdrant_url)\n",
    "\n",
    "model_path_st = '/Users/hissain/git/github/models/all-MiniLM-L6-v2'\n",
    "embedding_model = SentenceTransformer(model_path_st)\n",
    "\n",
    "TOP_K = 10\n",
    "TOP_N = 4\n",
    "SYM_W = 0.8\n",
    "SYN_W = 0.2\n",
    "NE_BOOST_FACTOR = 1.2\n",
    "NE_FULL_BOOST_FACTOR = 1.2\n",
    "\n",
    "def get_embeddings(texts):\n",
    "    return embedding_model.encode(texts, batch_size=32, show_progress_bar=True)\n",
    "\n",
    "def create_collection(dimension):\n",
    "    client.delete_collection(collection_name=collection_name)\n",
    "    client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=models.VectorParams(size=dimension, distance=models.Distance.COSINE),\n",
    "    )\n",
    "\n",
    "def upsert_points_with_metadata(embeddings, chunks, batch_size=100):\n",
    "    points = [\n",
    "        models.PointStruct(\n",
    "            id=i,\n",
    "            vector=embedding.tolist(),\n",
    "            payload={\"text\": chunk, \"url\": url, \"nes\": nes}\n",
    "        ) for i, (embedding, (chunk, url, nes)) in enumerate(zip(embeddings, chunks))\n",
    "    ]\n",
    "\n",
    "    for i in tqdm(range(0, len(points), batch_size), desc=\"Storing to Qdrant\"):\n",
    "        batch_points = points[i:i + batch_size]\n",
    "        client.upsert(collection_name=collection_name, points=batch_points)\n",
    "        time.sleep(0.01)\n",
    "\n",
    "def store_in_qdrant_with_metadata(chunks):\n",
    "    dimension = 384\n",
    "    create_collection(dimension)\n",
    "    chunk_texts = [chunk for chunk, _, _ in chunks]\n",
    "    embeddings = get_embeddings(chunk_texts)\n",
    "    upsert_points_with_metadata(embeddings, chunks)\n",
    "\n",
    "def search_points_with_metadata(query_text, k=TOP_K):\n",
    "    query_embedding = get_embeddings([query_text])[0]\n",
    "    search_result = client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=query_embedding.tolist(),\n",
    "        limit=k,\n",
    "        with_payload=True\n",
    "    )\n",
    "    return [{\"text\": hit.payload[\"text\"], \"url\": hit.payload[\"url\"], \"score\": hit.score} for hit in search_result]\n",
    "\n",
    "def init_bm25(corpus_texts):\n",
    "    tokenized_corpus = [text.split() for text in corpus_texts]\n",
    "    return BM25Okapi(tokenized_corpus)\n",
    "\n",
    "def calculate_bm25_scores(bm25, query_text):\n",
    "    tokenized_query = query_text.split()\n",
    "    return bm25.get_scores(tokenized_query)\n",
    "\n",
    "def extract_named_entities(text):\n",
    "    doc = nlp(text)\n",
    "    return [ent.text for ent in doc.ents]\n",
    "\n",
    "def boost_ne_scores(query_text, docs, bm25_scores, boost_factor=NE_BOOST_FACTOR, full_match_boost=NE_FULL_BOOST_FACTOR):\n",
    "    query_entities = extract_named_entities(query_text)\n",
    "    print(f\"Query Named Entities: {query_entities}\")\n",
    "    \n",
    "    boosted_scores = []\n",
    "    for idx, (doc, bm25_score) in enumerate(zip(docs, bm25_scores)):\n",
    "        doc_entities = extract_named_entities(doc[\"text\"])\n",
    "        matching_ne_count = sum(1 for ne in query_entities if ne in doc_entities)\n",
    "        full_match = all(ne in doc_entities for ne in query_entities)\n",
    "        ne_boost = 1 + (boost_factor * matching_ne_count)\n",
    "        if full_match:\n",
    "            ne_boost *= full_match_boost\n",
    "        boosted_scores.append(bm25_score * ne_boost)\n",
    "\n",
    "    print(f\"First-4 Boosted scores: {boosted_scores[:4]}\")          \n",
    "    return boosted_scores\n",
    "\n",
    "def get_top_n_chunks_by_combined_score(query_text, retrieved_docs, n=TOP_N, semantic_weight=SYM_W, keyword_weight=SYN_W):\n",
    "    \n",
    "    bm25 = init_bm25([doc[\"text\"] for doc in retrieved_docs])\n",
    "    bm25_scores = calculate_bm25_scores(bm25, query_text)\n",
    "    boosted_keyword_scores = boost_ne_scores(query_text, retrieved_docs, bm25_scores)\n",
    "\n",
    "    scored_chunks = []\n",
    "    \n",
    "    for idx, doc in enumerate(retrieved_docs):\n",
    "        semantic_score = doc[\"score\"]\n",
    "        keyword_score = boosted_keyword_scores[idx]\n",
    "        combined_score = (semantic_weight * semantic_score) + (keyword_weight * keyword_score)\n",
    "        scored_chunks.append({\"text\": doc[\"text\"], \"url\": doc[\"url\"], \"combined_score\": combined_score})\n",
    "\n",
    "    scored_chunks.sort(key=lambda n: n[\"combined_score\"], reverse=True)\n",
    "    print(f\"Top-4 Combined scores: {[s['combined_score'] for s in scored_chunks[:4]]}\")\n",
    "    return scored_chunks[:n]\n",
    "\n",
    "def search_points_with_metadata(query_text, k=TOP_K, n=TOP_N, semantic_weight=SYM_W, keyword_weight=SYN_W):\n",
    "    query_embedding = get_embeddings([query_text])[0]\n",
    "    search_result = client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=query_embedding.tolist(),\n",
    "        limit=k,\n",
    "        with_payload=True\n",
    "    )\n",
    "    \n",
    "    retrieved_docs = [{\"text\": hit.payload[\"text\"], \"url\": hit.payload[\"url\"], \"score\": hit.score} for hit in search_result]\n",
    "    \n",
    "    return get_top_n_chunks_by_combined_score(query_text, retrieved_docs, n=n, semantic_weight=semantic_weight, keyword_weight=keyword_weight)\n",
    "\n",
    "def process_streamed_response(response, buffer_size=5):\n",
    "    response_text, buffer = \"\", \"\"\n",
    "    for chunk in response.iter_content(chunk_size=None):\n",
    "        try:\n",
    "            data = json.loads(chunk.decode('utf-8'))\n",
    "            content = data.get(\"response\", \"\")\n",
    "            buffer += content\n",
    "\n",
    "            if len(buffer) >= buffer_size:\n",
    "                response_text += buffer\n",
    "                clear_output(wait=True)\n",
    "                display(Markdown(response_text))\n",
    "                buffer = \"\"\n",
    "                \n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "            \n",
    "    response_text += buffer\n",
    "    clear_output(wait=True)\n",
    "    display(Markdown(response_text))\n",
    "    return response_text\n",
    "\n",
    "def inspect(query, k=TOP_K, n=TOP_N):\n",
    "    retrieved_docs = search_points_with_metadata(query, k=k, n=n)\n",
    "    combined_docs = \"\\n\\n\".join([f\"Source: {doc['url']}\\n\\n{doc['text']}\" for doc in retrieved_docs])\n",
    "    rag_prompt = f\"Documents:\\n\\n<context>\\n\\n{combined_docs}\\n\\n</context>\\n\\nQuestion: {query}\\n\\nAnswer:\\n\"\n",
    "    print(rag_prompt)\n",
    "\n",
    "def ask(query, k=TOP_K, n=TOP_N):\n",
    "    retrieved_docs = search_points_with_metadata(query, k=k, n=n)\n",
    "    combined_docs = \"\\n\\n\".join([f\"Source: {doc['url']}\\n\\n{doc['text']}\" for doc in retrieved_docs])\n",
    "    inst = (\"Instruction: Please answer the following question based on following context.\"\n",
    "            \"If you do not find the answer within the following context, please respond,\"\n",
    "            \"'Answer not found in the context.' without speculation or general knowledge.\"\n",
    "            \"'Do not start with phrase like, 'according to the context', or anything similar.\")\n",
    "    rag_prompt = f\"{inst}\\n\\n<context>\\n\\n{combined_docs}\\n\\n</context>\\n\\nQuestion: {query}\\n\\nAnswer:\\n\"\n",
    "    payload = {\"model\": ollama_model_name, \"prompt\": rag_prompt, \"stream\": True}\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    response = session.post(ollama_url_gen, headers=headers, data=json.dumps(payload), stream=True)\n",
    "    response_text = process_streamed_response(response) if response.status_code == 200 else \"Request failed\"\n",
    "    return response_text\n",
    "    \n",
    "#try:\n",
    "store_in_qdrant_with_metadata(ne_chunks)\n",
    "print(f'Stored {len(scraped_chunks)} relevant chunks')\n",
    "#except Exception as e:\n",
    "print(f\"Error storing in Qdrant: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "51d8aa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(q):\n",
    "    return inspect(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4e5ba643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d03e4d336da0485f8d5c8e11ed112aeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Named Entities: ['Bangladesh Liberation War']\n",
      "First-4 Boosted scores: [1.1396155566920831, 1.1705233266605577, 0.962393849896497, 1.1984849241676128]\n",
      "Top-4 Combined scores: [0.7492975913384166, 0.7068857533321116, 0.6608509048335226, 0.6332947855925648]\n",
      "Documents:\n",
      "\n",
      "<context>\n",
      "\n",
      "Source: https://en.wikipedia.org/wiki/List_of_wars:_1990%E2%80%932002\n",
      "\n",
      "Table (List of wars: 1990‚Äì2002): | ('Started', 'Started') | ('Ended', 'Ended') | ('Name of Conflict', 'Name of Conflict') | ('Belligerents', 'Victorious party (if applicable)') | ('Belligerents', 'Defeated party (if applicable)') ||| 1993 | 2021 | Maoist insurgency in Bangladesh | Bangladesh | Maoist groups PBCP PBCP - J PBSP BCP GMF || 1994 | 1996 | Chiapas conflict | Mexico | Zapatista Army of National Liberation || 1994 | 1994 | 1994 Zapatista Uprising Part of the Chiapas conflict | Mexico | Zapatista Army of National Liberation || 1994 | 2018 | Insurgency in Ogaden | Ethiopia | Ogaden National Liberation Front || 1994 | 1994 | 1994 Bophuthatswana crisis | BDF Mutineers SADF | Government of Bophuthatswana Afrikaner Volksfront AWB ||\n",
      "\n",
      "Source: https://en.wikipedia.org/wiki/List_of_wars:_1945%E2%80%931989\n",
      "\n",
      "Table (1970‚Äì1979): | ('Started', 'Started') | ('Ended', 'Ended') | ('Name of conflict', 'Name of conflict') | ('Belligerents', 'Victorious party (if applicable)') | ('Belligerents', 'Defeated party (if applicable)') ||| 1971 | 1971 | Seizure of Abu Musa and the Greater and Lesser Tunbs | Iran | Sharjah || 1972 | 1974 | First Eritrean Civil War Part of the Ethiopian Civil War and the Eritrean War of Independence | EPLF | ELF || 1972 | 1975 | 1972‚Äì1975 Bangladesh insurgency | Bangladesh | Gonobahini  Purba Banglar Sarbahara Party || 1972 | Ongoing | Maoist insurgency in Turkey | Turkey | TKP/ML-Tƒ∞KKO  MKP-HKO-PHG  MLKP Maoist Party Centre THKP-C (Dissolved) THKO (Dissolved) ||\n",
      "\n",
      "Source: https://en.wikipedia.org/wiki/List_of_wars:_1945%E2%80%931989\n",
      "\n",
      "Table (1970‚Äì1979): | ('Started', 'Started') | ('Ended', 'Ended') | ('Name of conflict', 'Name of conflict') | ('Belligerents', 'Victorious party (if applicable)') | ('Belligerents', 'Defeated party (if applicable)') ||| 1970 | 1971 | Reggio revolt | Italy | Christian Democracy Italian Social Movement Italian Social Democratic Party National Italian Workers' Union 'Ndrangheta || 1970 | 1971 | Black September | Jordan | PLO ¬†Syria || 1970 | 1970 | Corrective Movement (Syria) | Assad loyalists | Syrian Government  Syrian Ba'ath Party || 1971 | 1971 | 1971 Ugandan coup d'√©tat | Ugandan putschists Rebel military Rebel police Supported by:  Israel  United Kingdom  United States | Ugandan government Loyal state institutions || 1971 | 1971 | Bangladesh Liberation War Part of the Indo-Pakistani wars and conflicts | Bangladesh ¬†India | Pakistan || 1971 | 1971 | 1971 JVP insurrection | Ceylon | JVP ||\n",
      "\n",
      "Source: https://en.wikipedia.org/wiki/List_of_wars:_2003%E2%80%93present\n",
      "\n",
      "Table (2003‚Äì2009): | ('Started', 'Started') | ('Ended', 'Ended') | ('Name of conflict', 'Name of conflict') | ('Belligerents', 'Victorious party (if applicable)') | ('Belligerents', 'Defeated party (if applicable)') ||| 2008 | 2011 | Cambodian ‚Äì Thai border dispute | Cambodia | Thailand || 2008 | 2008 | 2008 Bangladesh India border clash | Bangladesh | India || 2008 | 2008 | Russo-Georgian War | Russia ¬†South Ossetia ¬†Abkhazia | Georgia || 2008 | 2008 | 2008 Kufra conflict | Libya | Toubou Front for the Salvation of Libya || 2008 | 2009 | Gaza War Part of the Gaza‚ÄìIsrael conflict | Israel | Gaza Strip  Hamas PFLP Palestinian Islamic Jihad Fatah Popular Resistance Councils ||\n",
      "\n",
      "</context>\n",
      "\n",
      "Question: When was Bangladesh Liberation War happened?\n",
      "\n",
      "Answer:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = ask(\"When was Bangladesh Liberation War happened?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "82154565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38072ef1b3a149678c43fe48c8d0ce1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Named Entities: ['Bangladesh Liberation War']\n",
      "First-4 Boosted scores: [1.7677708982813318, 1.0101032420239109, 1.0415550681220305, 0.7942953294910778]\n",
      "Top-4 Combined scores: [0.8774596196562663, 0.6610719284047821, 0.6460470456244062, 0.5993649570453428]\n",
      "Documents:\n",
      "\n",
      "<context>\n",
      "\n",
      "Source: https://en.wikipedia.org/wiki/List_of_wars:_1990%E2%80%932002\n",
      "\n",
      "Table (List of wars: 1990‚Äì2002): | ('Started', 'Started') | ('Ended', 'Ended') | ('Name of Conflict', 'Name of Conflict') | ('Belligerents', 'Victorious party (if applicable)') | ('Belligerents', 'Defeated party (if applicable)') ||| 1993 | 2021 | Maoist insurgency in Bangladesh | Bangladesh | Maoist groups PBCP PBCP - J PBSP BCP GMF || 1994 | 1996 | Chiapas conflict | Mexico | Zapatista Army of National Liberation || 1994 | 1994 | 1994 Zapatista Uprising Part of the Chiapas conflict | Mexico | Zapatista Army of National Liberation || 1994 | 2018 | Insurgency in Ogaden | Ethiopia | Ogaden National Liberation Front || 1994 | 1994 | 1994 Bophuthatswana crisis | BDF Mutineers SADF | Government of Bophuthatswana Afrikaner Volksfront AWB ||\n",
      "\n",
      "Source: https://en.wikipedia.org/wiki/List_of_wars:_1945%E2%80%931989\n",
      "\n",
      "Table (1970‚Äì1979): | ('Started', 'Started') | ('Ended', 'Ended') | ('Name of conflict', 'Name of conflict') | ('Belligerents', 'Victorious party (if applicable)') | ('Belligerents', 'Defeated party (if applicable)') ||| 1971 | 1971 | Seizure of Abu Musa and the Greater and Lesser Tunbs | Iran | Sharjah || 1972 | 1974 | First Eritrean Civil War Part of the Ethiopian Civil War and the Eritrean War of Independence | EPLF | ELF || 1972 | 1975 | 1972‚Äì1975 Bangladesh insurgency | Bangladesh | Gonobahini  Purba Banglar Sarbahara Party || 1972 | Ongoing | Maoist insurgency in Turkey | Turkey | TKP/ML-Tƒ∞KKO  MKP-HKO-PHG  MLKP Maoist Party Centre THKP-C (Dissolved) THKO (Dissolved) ||\n",
      "\n",
      "Source: https://en.wikipedia.org/wiki/List_of_wars:_2003%E2%80%93present\n",
      "\n",
      "Table (2020‚Äì2024): | ('Started', 'Started') | ('Ended', 'Ended') | ('Name of conflict', 'Name of conflict') | ('Belligerents', 'Victorious party (if applicable)') | ('Belligerents', 'Defeated party (if applicable)') ||| 2022 | Ongoing | Chittagong Hill Tracts conflict Part of the Terrorism in Bangladesh | Bangladesh PCJSS - MN Larma UPDF - D Mog Party ( MNP ) | PCJSS UPDF Kuki - Chin National Front || 2022 | Ongoing | Russian invasion of Ukraine Part of the Russo-Ukrainian War | Russia ¬†Donetsk People's Republic ¬†Luhansk People's Republic show Supported by: | Ukraine Ukrainian diaspora volunteers Foreign volunteers show Supported by: ||\n",
      "\n",
      "Source: https://en.wikipedia.org/wiki/List_of_wars:_2003%E2%80%93present\n",
      "\n",
      "Table (2003‚Äì2009): | ('Started', 'Started') | ('Ended', 'Ended') | ('Name of conflict', 'Name of conflict') | ('Belligerents', 'Victorious party (if applicable)') | ('Belligerents', 'Defeated party (if applicable)') ||| 2004 | Ongoing | Sistan and Baluchestan insurgency Part of the Balochistan conflict | Iran | Jundallah ( 2004 ‚Äì 11 ) Harakat Ansar ( 2012 ‚Äì 13 ) Jaish ul - Adl ( 2013 ‚Äì Present ) Ansar Al - Furqan ( 2013 ‚Äì Present ) || 2005 | 2005 | 2005 Bangladesh India border clash | India | Bangladesh || 2005 | Ongoing | Insurgency in Paraguay | Paraguay Supported by: ¬†United States ¬†Colombia Vigilante self-defense groups | Paraguayan People's Army (EPP)  Armed Peasant Association (ACA)  Army of Marshal L√≥pez (EML) (from 2016) Supported by:  FARC (until 2016)  Manuel Rodr√≠guez Patriotic Front (alleged) ||\n",
      "\n",
      "</context>\n",
      "\n",
      "Question: How many died in Bangladesh Liberation War?\n",
      "\n",
      "Answer:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = ask(\"How many died in Bangladesh Liberation War?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3eb7e384",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30cb94d6e17e417d811f3a1e41d62e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Named Entities: ['Federal War']\n",
      "First-4 Boosted scores: [0.7611330415888826, 0.6212661035132957, 3.668201340734459, 0.5843579405690478]\n",
      "Top-4 Combined scores: [1.1361037881468918, 0.5778782563177766, 0.5473089571949658, 0.5378419119988755]\n",
      "Documents:\n",
      "\n",
      "<context>\n",
      "\n",
      "Source: https://en.wikipedia.org/wiki/List_of_wars_by_death_toll\n",
      "\n",
      "Table (List): | War | Death range | Date | Combatants | Location ||| Arab - Israeli conflict | 0. 15 million | 1948 [ g ] ‚Äì present | Israel vs. Arab League, Iran, Hezbollah, Hamas, and the Houthi movement | Levant || Lebanese Civil War | 0.12‚Äì0.15 million | 1975‚Äì1990 | Multiple sides | Levant || Greek Civil War | 0.08‚Äì0.15 million | 1946‚Äì1949 | Kingdom of Greece vs. Provisional Democratic Government | Balkans and Peloponnese Peninsula || Yugoslav Wars | 0.13‚Äì0.14 million | 1991‚Äì2001 | Separatist forces and NATO vs. Socialist Federal Republic of Yugoslavia, later Federal Republic of Yugoslavia | Balkans || Irish Nine Year's War | 0.13 million | 1593‚Äì1603 | Kingdom of England vs. Irish rebels | Ireland || Chaco War | 0.08‚Äì0.13 million | 1932‚Äì1935 | Paraguay vs. Bolivia | Paraguay and Bolivia || Federal War | 0.1 million | 1859‚Äì1863 | Federalists vs. Conservatives | Venezuela ||\n",
      "\n",
      "Source: https://en.wikipedia.org/wiki/List_of_wars:_1800%E2%80%931899\n",
      "\n",
      "Contents List of wars : 1800 ‚Äì 1899 This article provides a list of wars occurring between 1800 and 1899. Conflicts of this era include the Napoleonic Wars in Europe, the American Civil War in North America, the Taiping Rebellion in Asia, the Paraguayan War in South America, the Zulu War in Africa, and the Australian frontier wars in Oceania. 1800 ‚Äì 1810\n",
      "\n",
      "Source: https://en.wikipedia.org/wiki/List_of_wars_by_death_toll\n",
      "\n",
      "Table (List): | War | Death range | Date | Combatants | Location ||| Panthay Rebellion | 1 million | 1856 ‚Äì 1873 | Qing Dynasty vs. Pingnan Guo | China || Seven Years' War | 1 million | 1756‚Äì1763 | Great Britain, Kingdom of Prussia, Hanover, Portugal, and allies vs. Kingdom of France, Habsburg empire, Saxony, Spain, and allies | Global || American Civil War | 0.6‚Äì1 million | 1861‚Äì1865 | United States vs. Confederate States | North America || First Sudanese Civil War | 0.5‚Äì1 million | 1955‚Äì1972 | Anglo-Egyptian Sudan, later Democratic Republic of the Sudan vs. Sudan Defence Force | Sudan || First Indochina War | 0.4‚Äì0.84 million | 1946‚Äì1954 | Viet Minh, Pathet Lao, and Khmer Issarak vs. French Union | Indochina || Burundian Civil War | 0.55‚Äì0.8 million | 1993‚Äì2005 | Burundi vs. Ethnic Hutu vs. Tutsi Militants | Rwanda and Burundi ||\n",
      "\n",
      "Source: https://en.wikipedia.org/wiki/List_of_wars:_1800%E2%80%931899\n",
      "\n",
      "Table (1840‚Äì1849): | ('Start', 'Start') | ('Finish', 'Finish') | ('Name of conflict', 'Name of conflict') | ('Belligerents', 'Victorious party (if applicable)') | ('Belligerents', 'Defeated party (if applicable)') ||| 1846 | 1847 | Seventh Xhosa War | British Empire | Xhosa Tribes || 1846 | 1849 | Second Carlist War War of the Madrugadores | Forces of Queen Isabella II of Spain | Carlists || 1846 | 1848 | Mexican‚ÄìAmerican War | United States | Mexico || 1846 | 1848 | Wanganui Campaign Part of the New Zealand Wars | British Empire  British Settlers  MƒÅori Kupapa | MƒÅori Iwis || 1847 | 1847 | Sonderbund War | Swiss Confederation | Sonderbund || 1847 | 1850 | Sierra Gorda Rebellion | Mexico | Tax Resisters || 1847 | 1855 | Cayuse War | United States | Cayuse ||\n",
      "\n",
      "</context>\n",
      "\n",
      "Question: When was Federal War happened?\n",
      "\n",
      "Answer:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = ask(\"When was Federal War happened?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7782d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ask(\"When did Quasi-War happend?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13817562",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ask(\"Where did Second Congo War happend?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a653292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ask(\"What types of killings are excluded in the list of war by death toll?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa182603",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ask(\"Which war started in 1945 ended in 1949?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a809a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ask(\"Ethiopian Empire vs. Emirate of Harar?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
