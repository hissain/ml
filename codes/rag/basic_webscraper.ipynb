{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc264dcf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4408848f61f9437aa4a5921c40224dc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing URLs:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 44\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "from transformers import AutoTokenizer\n",
    "import re\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "model_path = '/Users/hissain/git/github/models/all-MiniLM-L6-v2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "def init_driver():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    service = Service()\n",
    "    return webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "def extract_text_from_url(url, driver):\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    soup = soup.body\n",
    "    if soup is None: return \"\" \n",
    "    for script in soup([\"script\", \"style\", \"footer\", \"header\", \"nav\", \"a\", \"table\"]):\n",
    "        script.decompose()\n",
    "    return soup.get_text(separator=\" \")\n",
    "\n",
    "def extract_and_prepare_table_chunks(url, driver, tokenizer, max_tokens=512):\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "\n",
    "    html_source = driver.page_source\n",
    "    tables = pd.read_html(StringIO(html_source))\n",
    "    all_chunks = []\n",
    "\n",
    "    for df in tables:\n",
    "        chunks, current_chunk = [], \"\"\n",
    "        header_text = \"Table Headers: \" + \", \".join(map(str, df.columns))\n",
    "        header_tokens = tokenizer.encode(header_text)\n",
    "\n",
    "        if len(header_tokens) > max_tokens:\n",
    "            chunks.extend(\n",
    "                [{\"text\": header_text[i:i+max_tokens], \"url\": url} for i in range(0, len(header_text), max_tokens)]\n",
    "            )\n",
    "        else:\n",
    "            current_chunk += header_text + \"\\n\"\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            row_str = \" | \".join([f\"{col}: {str(val)}\" for col, val in row.items()])\n",
    "            row_tokens = tokenizer.encode(row_str)\n",
    "\n",
    "            if len(tokenizer.encode(current_chunk)) + len(row_tokens) > max_tokens:\n",
    "                chunks.append({\"text\": current_chunk.strip(), \"url\": url})\n",
    "                current_chunk = header_text + \"\\n\" + row_str + \"\\n\"\n",
    "            else:\n",
    "                current_chunk += row_str + \"\\n\"\n",
    "\n",
    "        if current_chunk:\n",
    "            chunks.append({\"text\": current_chunk.strip(), \"url\": url})\n",
    "\n",
    "        all_chunks.extend(chunks)\n",
    "\n",
    "    return all_chunks\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s.,!?\\'\"()-]', '', text)\n",
    "    return text.strip().lower()\n",
    "\n",
    "def split_sentences(text):\n",
    "    return re.split(r'(?<=[.!?]) +', text)\n",
    "\n",
    "def count_tokens(text):\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "def partition_sentences(sentences, url, max_tokens=400, overlap=1):\n",
    "    chunks, current_chunk = [], []\n",
    "    current_tokens = 0\n",
    "\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        sentence_tokens = count_tokens(sentence)\n",
    "        \n",
    "        if current_tokens + sentence_tokens > max_tokens:\n",
    "            chunks.append({\"text\": \" \".join(map(str, current_chunk)), \"url\": url})\n",
    "            current_chunk = current_chunk[-overlap:]\n",
    "            current_tokens = count_tokens(\" \".join(map(str, current_chunk)))\n",
    "\n",
    "        current_chunk.append(sentence)\n",
    "        current_tokens += sentence_tokens\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append({\"text\": \" \".join(map(str, current_chunk)), \"url\": url})\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def process_urls(urls):\n",
    "    driver = init_driver()\n",
    "    all_chunks = []\n",
    "    \n",
    "    for url in tqdm(urls, desc=\"Processing URLs\"):\n",
    "        try:\n",
    "            raw_text = extract_text_from_url(url, driver)\n",
    "            clean_text_content = clean_text(raw_text)\n",
    "            sentences = split_sentences(clean_text_content)\n",
    "            chunks = partition_sentences(sentences, url, max_tokens=400, overlap=1)\n",
    "            all_chunks.extend(chunks)\n",
    "            \n",
    "            table_chunks = extract_and_prepare_table_chunks(url, driver, tokenizer)\n",
    "            all_chunks.extend(table_chunks)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {url}: {e}\")\n",
    "    \n",
    "    return all_chunks\n",
    "\n",
    "urls = [\n",
    "    \"https://en.wikipedia.org/wiki/List_of_wars_by_death_toll\",\n",
    "]\n",
    "\n",
    "rag_chunks = process_urls(urls)\n",
    "print(f\"Total chunks: {len(rag_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a071ac5f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1:\n",
      "Text: . bbc news . 2014-09-23 . retrieved 2024-10-03 . . . levy, jack s. (1983). . university press of kentucky. . . clodfelter, micheal (2008). . internet archive. jefferson, n.c. mcfarland. . nolan, cathal j. (2006). . internet archive. westport, conn. greenwood press. . momodu, samuel (2016-07-25). . retrieved 2024-10-02 . . remilitari.com . retrieved 2024-10-02 . (pdf) . yi, ki-baek (1984). . internet archive. cambridge, mass. published for the harvard-yenching institute by harvard university press. . shi, li. . deeplogic. salvador, antonio caridad (2018-05-23). . cuadernos de historia contemporánea (in spanish). 40  149167. . . . the costs of war . retrieved 2024-10-03 . . www.pbs.org . retrieved 2024-09-29 . . www.forcesnews.com . 2021-02-28 . retrieved 2024-09-29 . gillespie, caitlin c. (2018-01-15). . oxford university press.\n",
      "URL: https://en.wikipedia.org/wiki/List_of_wars_by_death_toll\n",
      "\n",
      "Chunk 2:\n",
      "Text: oxford university press. . crane, nicholas (2016-10-13). . orion. . copeland, tim (2014-09-15). . amberley publishing limited. . . bbc news русская служба (in russian). 2024-09-20 . retrieved 2024-09-30 . . 2024-02-25 . retrieved 2024-09-30 . (pdf) . (pdf) . pancevski, bojan (september 17, 2024). . silbey, david (2008-03-04). . macmillan. . dasgupta, k. k. (1960). . peoples of publishing house. (pdf) . raychaudhuri, h. (2006). . cosmo publications. p. 268,305. isbn 978-81-307-0291-9. retrieved 27 june 2019. . amnesty international . 23 november 1998 . retrieved 2024-09-30 . edgar danés rojas (2008). noticias del edén la iglesia católica y la constitución mexicana . tamaulipas universidad autónoma de tamaulipas, pp. 82. isbn 978-970-819-063-3. . www.tc-america.org . retrieved 2024-10-02 . . onwar.com .\n",
      "URL: https://en.wikipedia.org/wiki/List_of_wars_by_death_toll\n",
      "\n",
      "Chunk 3:\n",
      "Text: onwar.com . retrieved 2024-10-02 . (pdf) . archived from (pdf) on 2011-07-20. . acled . retrieved 2024-10-01 . , pp. 133134 . reliefweb.int . 1999-11-04 . retrieved 2024-10-02 . . . archived from on 2023-06-06 . retrieved 2024-10-02 . . archived from on 2008-03-02 . retrieved 2024-10-02 . kramer, mark (march 2005). . europe-asia studies . 57 (2) 209290. . reinke, sarah (2005). (in german). gfbv. , p. 46. noorani, a.g. (316 march 2001), \" \", frontline, 18 (5), retrieved 8 september 2014, \"the lowest estimates, even those offered privately by apologists of the military government, came to at least ten times the number of murders with which previously the razakars were officially accused...\" romero-prieto, julio enrique meisel-roca, adolfo enrique (2 june 2019). (in spanish). the greek and persian wars 499-386 bc . philip de souza. 25 january 2003. p. 41. . . 2012-07-03 . retrieved 2024-10-01 . briggs, billy (2007-02-02). . the guardian . .\n",
      "URL: https://en.wikipedia.org/wiki/List_of_wars_by_death_toll\n",
      "\n",
      "Chunk 4:\n",
      "Text: . retrieved 2024-10-01 . singer, joel david small, melvin (1972). . wiley. . schanzer, jonathan. (pdf) . archived from (pdf) on 2012-03-20. vandewalle, dirk (2012-03-26). . cambridge university press. p. 31. . ahmida, ali abdullatif (2021). . routledge. . boca, angelo del (2010-12-14). . springer. p. 5. . . users.erols.com . retrieved 2024-09-30 . campos, ângela (2008-11-20). . lusotopie. recherches politiques internationales sur les espaces issus de l'histoire et de la colonisation portugaises (xv(2)) 107126. . . . www.onwar.com . retrieved 2024-09-30 . waiss, óscar (1954). nacionalismo y socialismo en américa latina. prensa latinoamericana, pp. 17. esta cifra carece de fundamento e implicaría prácticamente la perdida total de las fuerzas de combate de ambos bandos. (pdf) . . 2019-05-17 . retrieved 2024-10-02 . . dumas, s. vedel-petersen, k.o. (1923).\n",
      "URL: https://en.wikipedia.org/wiki/List_of_wars_by_death_toll\n",
      "\n",
      "Chunk 5:\n",
      "Text: (1923). . oxford clarendon press. pp. 59. dabanga (2024-05-02). . dabanga radio tv online . retrieved 2024-09-30 . . bloomberg.com . 2024-05-09 . retrieved 2024-09-30 . . 2020-08-31. archived from on 2020-08-31 . retrieved 2024-10-03 . . 2016-12-18. archived from on 2016-12-18 . retrieved 2024-10-01 . . the lancet . 404 (10449). july 20, 2024. . 2023-12-17. archived from on 2023-12-17 . retrieved 2024-10-01 . . november 21, 2023. . 9 september 2024. cook, chris (1995). world political almanac (3rd ed.). facts on file. . . www.britannica.com . 2024-09-27 . retrieved 2024-10-01 . ufheil-somers, amanda (1990-01-10). . merip . retrieved 2024-10-01 . keridis, dimitris (2022-06-06). . rowman  littlefield. p. 54. . bercovitch, jacob jackson, richard (1997). . congressional quarterly. . .\n",
      "URL: https://en.wikipedia.org/wiki/List_of_wars_by_death_toll\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, chunk in enumerate(rag_chunks[15:20]):\n",
    "    print(f\"Chunk {i+1}:\\nText: {chunk['text']}\\nURL: {chunk['url']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c686a7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "951b9fb7e8de48dd9d5bcdb092a767f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 44 chunks\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from qdrant_client import QdrantClient, models\n",
    "from tqdm.notebook import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from IPython.display import display, clear_output, Markdown\n",
    "import requests\n",
    "import json\n",
    "import asyncio\n",
    "\n",
    "session = requests.Session()\n",
    "session.headers.update({\"Connection\": \"keep-alive\", \"Content-Type\": \"application/json\"})\n",
    "\n",
    "qdrant_url = \"http://localhost:6333\"\n",
    "collection_name = \"github_collection\"\n",
    "\n",
    "ollama_url_inf = \"http://localhost:11434/api/show\"\n",
    "ollama_url_emb = \"http://localhost:11434/api/embeddings\"\n",
    "ollama_url_gen = \"http://localhost:11434/api/generate\"\n",
    "ollama_model_name = \"llama3.2:latest\"\n",
    "\n",
    "client = QdrantClient(url=qdrant_url)\n",
    "embedding_model = SentenceTransformer(model_path)\n",
    "\n",
    "def get_embedding(text):\n",
    "    return embedding_model.encode(text)\n",
    "\n",
    "def create_collection(dimension):\n",
    "    try:\n",
    "        client.delete_collection(collection_name=collection_name)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=models.VectorParams(size=dimension, distance=models.Distance.COSINE),\n",
    "    )\n",
    "    \n",
    "def upsert_points_with_metadata(embeddings, chunks):\n",
    "    points = [\n",
    "        models.PointStruct(id=i, vector=embedding.tolist(), payload={\"text\": chunk[\"text\"], \"url\": chunk[\"url\"]})\n",
    "        for i, (embedding, chunk) in enumerate(zip(embeddings, chunks))\n",
    "    ]\n",
    "    client.upsert(collection_name=collection_name, points=points)\n",
    "\n",
    "def store_in_qdrant_with_metadata(chunks):\n",
    "    dimension = 384  # Dimension for 'all-MiniLM-L6-v2'\n",
    "    create_collection(dimension)\n",
    "    embeddings = [get_embedding(chunk[\"text\"]) for chunk in tqdm(chunks, desc=\"Generating embeddings\")]\n",
    "    upsert_points_with_metadata(embeddings, chunks)\n",
    "\n",
    "def search_points_with_metadata(query_embedding, k=3):\n",
    "    search_result = client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=query_embedding.tolist(),\n",
    "        limit=k,\n",
    "        with_payload=True\n",
    "    )\n",
    "    return [{\"text\": hit.payload[\"text\"], \"url\": hit.payload[\"url\"]} for hit in search_result]\n",
    "\n",
    "try:\n",
    "    store_in_qdrant_with_metadata(rag_chunks)\n",
    "    print(f'Stored {len(rag_chunks)} chunks')\n",
    "except Exception as e:\n",
    "    print(f\"Error storing in Qdrant: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8437f1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(query, k=3, p=False):\n",
    "    \n",
    "    query_embedding = get_embedding(query)\n",
    "    retrieved_docs = search_points_with_metadata(query_embedding, k)\n",
    "    \n",
    "    combined_docs = \"\\n\\n\".join([f\"Source: {doc['url']}\\n{doc['text']}\" for doc in retrieved_docs])\n",
    "    inst = \"Instruction: If you do not find the answer in the CONTEXT, just say you don't know.\"\n",
    "    rag_prompt = f\"{inst}\\n\\n<CONTEXT>\\n{combined_docs}\\n</CONTEXT>\\n\\nQuery: {query}\\n\"\n",
    "    if p:\n",
    "        print(rag_prompt)\n",
    "        \n",
    "    payload = {\"model\": ollama_model_name, \"prompt\": rag_prompt, \"stream\": True}\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    response_text = \"\"\n",
    "    if p:\n",
    "        response_text = rag_prompt\n",
    "    buffer = \"\"\n",
    "\n",
    "    response = session.post(ollama_url_gen, headers=headers, data=json.dumps(payload), stream=True)\n",
    "\n",
    "    # Process the response content as it arrives\n",
    "    if response.status_code == 200:\n",
    "        for chunk in response.iter_content(chunk_size=None):\n",
    "            try:\n",
    "                data = json.loads(chunk.decode('utf-8'))\n",
    "                content = data.get(\"response\", \"\")\n",
    "                buffer += content\n",
    "\n",
    "                # Display output every few characters for real-time effect\n",
    "                if len(buffer) > 10:\n",
    "                    response_text += buffer\n",
    "                    clear_output(wait=True)\n",
    "                    display(Markdown(response_text))\n",
    "                    buffer = \"\"\n",
    "                    \n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "\n",
    "        # Display any remaining buffered content\n",
    "        response_text += buffer\n",
    "        clear_output(wait=True)\n",
    "        display(Markdown(response_text))\n",
    "    else:\n",
    "        print(\"Request failed:\", response.status_code, response.text)\n",
    "\n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32f89900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Instruction: If you do not find the answer in the CONTEXT, just say you don't know.\n",
       "\n",
       "<CONTEXT>\n",
       "Source: https://en.wikipedia.org/wiki/List_of_wars_by_death_toll\n",
       "Table Headers: War, Death range, Date, Combatants, Location\n",
       "War: South Sudanese Civil War | Death range: 0.38 million[143] | Date: 2013–2020 | Combatants: South Sudan vs. SPLM-IO, Nuer White Army, and SSDM | Location: South Sudan\n",
       "War: Yemeni civil war | Death range: 0.15–0.37 million[144][145] | Date: 2014–present | Combatants: Multiple sides | Location: Yemen\n",
       "War: Boko Haram insurgency | Death range: 0.03–0.35 million[146] | Date: 2009–present | Combatants: Multinational Joint Task Force vs. Boko Haram | Location: Nigeria\n",
       "War: Franco-Dutch War | Death range: 0.34 million[147] | Date: 1672–1678 | Combatants: Kingdom of France vs. Dutch Republic | Location: Western Europe\n",
       "War: Ottoman–Venetian wars | Death range: 0.34 million[148][149] | Date: 1415–1718 | Combatants: Ottoman Empire vs. Holy League | Location: Mediterranean Sea, Greece and Cyprus\n",
       "War: Liberian Civil Wars and Sierra Leone Civil War | Death range: 0.3–0.32 million[150][151][152] | Date: 1989–2003 | Combatants: Liberian government, Revolutionary United Front vs. National Patriotic Front of Liberia, Liberians United for Reconciliation and Democracy, Movement for Democracy in Liberia, Sierra Leone | Location: West Africa\n",
       "War: Goguryeo–Sui War | Death range: 0.3 million[153][154] | Date: 598–614 | Combatants: Sui Dynasty vs. Goguryeo | Location: Manchuria and Korean Peninsula\n",
       "War: Carlist Wars | Death range: 0.3 million[155] | Date: 1833–1876 | Combatants: Carlists vs. Liberals and Republicans | Location: Iberian Peninsula\n",
       "War: Iraqi conflict | Death range: 0.27–0.3 million[156] | Date: 2003–2017 | Combatants: Multiple sides | Location: Levant\n",
       "War: Gulf War | Death range: 0.17–0.3 million[157][158] | Date: 1990–1991[e] | Combatants: Kuwait and the United States-led coalition vs. Iraq | Location: Kuwait and Iraq\n",
       "\n",
       "Source: https://en.wikipedia.org/wiki/List_of_wars_by_death_toll\n",
       "Table Headers: War, Death range, Date, Combatants, Location\n",
       "War: Sri Lankan Civil War | Death range: 0.08–0.17 million[200][201] | Date: 1983[f]–2009 | Combatants: Sri Lankan government vs. Separatist Liberation Tigers of Tamil Eelam | Location: Sri Lanka\n",
       "War: Russo-Japanese War | Death range: 0.12–0.16 million[203] | Date: 1904–1905 | Combatants: Empire of Japan vs. Russian Empire | Location: East Asia\n",
       "War: Sudanese civil war (2023–present) | Death range: 0.15 million[204][205] | Date: 2023–present | Combatants: Sudan and allies vs. Rapid Support Forces and allies | Location: Sudan\n",
       "War: Algerian Civil War | Death range: 0.15 million[206] | Date: 1992–2002 | Combatants: Multiple sides | Location: North Africa\n",
       "War: Arab-Israeli conflict | Death range: 0.15 million[207][208][209][210] | Date: 1948[g]–present | Combatants: Israel vs. Arab League, Iran, Hezbollah, Hamas, and the Houthi movement | Location: Levant\n",
       "War: Lebanese Civil War | Death range: 0.12–0.15 million[212][213][214] | Date: 1975–1990 | Combatants: Multiple sides | Location: Levant\n",
       "War: Greek Civil War | Death range: 0.08–0.15 million[215][216] | Date: 1946–1949 | Combatants: Kingdom of Greece vs. Provisional Democratic Government | Location: Balkans and Peloponnese Peninsula\n",
       "War: Yugoslav Wars | Death range: 0.13–0.14 million[217][218] | Date: 1991–2001 | Combatants: Separatist forces and NATO vs. Socialist Federal Republic of Yugoslavia, later Federal Republic of Yugoslavia | Location: Balkans\n",
       "War: Irish Nine Year's War | Death range: 0.13 million[219] | Date: 1593–1603 | Combatants: Kingdom of England vs. Irish rebels | Location: Ireland\n",
       "War: Chaco War | Death range: 0.08–0.13 million[220][221][222] | Date: 1932–1935 | Combatants: Paraguay vs. Bolivia | Location: Paraguay and Bolivia\n",
       "\n",
       "Source: https://en.wikipedia.org/wiki/List_of_wars_by_death_toll\n",
       "Table Headers: War, Death range, Date, Combatants, Location\n",
       "War: World War II | Death range: 50–85 million[4][5][6] | Date: 1939–1945 | Combatants: Allied Powers vs. Axis Powers | Location: Global\n",
       "War: Mongol invasions and conquests | Death range: 20–60 million[7][8][9][10] | Date: 1207–1405 | Combatants: Mongol Empire vs. various states in Eurasia | Location: Asia and Europe\n",
       "War: Three Kingdoms | Death range: 34 million[10] | Date: 220–280 | Combatants: Multiple sides | Location: China\n",
       "War: Taiping Rebellion | Death range: 20–30 million[11][12] | Date: 1850–1864 | Combatants: Qing Dynasty vs. Taiping Heavenly Kingdom | Location: China\n",
       "War: World War I | Death range: 15–30 million[13][14] | Date: 1914–1918 | Combatants: Allied Powers vs. Central Powers | Location: Global\n",
       "War: Manchu Conquest of China | Death range: 25 million[15][16] | Date: 1618–1683 | Combatants: Manchu vs. Ming Dynasty | Location: China\n",
       "War: Conquests of Timur | Death range: 7–20 million[10] | Date: 1369–1405 | Combatants: Timurid Empire vs. various states in Asia | Location: Central Asia, West Asia, and South Asia\n",
       "War: An Lushan rebellion | Death range: 13 million[17] | Date: 754–763 | Combatants: Tang Dynasty and Uyghur Khaganate vs. Yan Dynasty | Location: China\n",
       "War: Thirty Years' War | Death range: 4–12 million[18] | Date: 1618–1648 | Combatants: Anti-Imperial Alliance vs. Imperial Alliance | Location: Europe\n",
       "War: Spanish conquest of Mexico | Death range: 10.5 million[19] | Date: 1519–1530 | Combatants: Spanish Empire and allies vs. Aztec Empire and allies | Location: Mexico\n",
       "War: Spanish conquest of the Inca Empire | Death range: 10 million[20] | Date: 1533–1572 | Combatants: Spanish Empire vs. Inca Empire | Location: South America\n",
       "</CONTEXT>\n",
       "\n",
       "Query: Bangladesh Liberation War data?\n",
       "I don't know."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = ask(\"Bangladesh Liberation War data?\", p=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f9187c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_url_chat = \"http://localhost:11434/api/chat\"\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "def chat(query, k=2, p=False, stream=True):\n",
    "    global chat_history\n",
    "    \n",
    "    query_embedding = get_embedding(query)\n",
    "    retrieved_docs = search_points_with_metadata(query_embedding, k)\n",
    "    \n",
    "    combined_docs = \"\\n\\n\".join([f\"Source: {doc['url']}\\n{doc['text']}\" for doc in retrieved_docs])\n",
    "    inst = \"Instruction: If you do not find the answer in the context, just say you don't know.\"\n",
    "    rag_prompt = f\"{inst}\\n\\n<context>\\n{combined_docs}\\n</context>\\n\\nQuery: {query}\\nAnswer:\"\n",
    "    if p:\n",
    "        print(rag_prompt)\n",
    "        \n",
    "    chat_history.append({\"role\": \"user\", \"content\": rag_prompt})\n",
    "    payload = {\"model\": ollama_model_name, \"messages\": chat_history, \"stream\": stream}\n",
    "    headers = {\"Connection\": \"keep-alive\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "    response_text = \"\"\n",
    "    buffer = \"\"\n",
    "\n",
    "    response = session.post(ollama_url_chat, data=json.dumps(payload), stream=stream)\n",
    "\n",
    "    # Process the response content as it arrives\n",
    "    if response.status_code == 200:\n",
    "        for chunk in response.iter_content(chunk_size=None):\n",
    "            try:\n",
    "                data = json.loads(chunk.decode('utf-8'))\n",
    "                content = data.get(\"message\", {}).get(\"content\", \"\")\n",
    "                buffer += content\n",
    "\n",
    "                # Display output every few characters for real-time effect\n",
    "                if len(buffer) > 10:\n",
    "                    response_text += buffer\n",
    "                    clear_output(wait=True)\n",
    "                    display(Markdown(response_text))\n",
    "                    buffer = \"\"\n",
    "                    \n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "\n",
    "        # Display any remaining buffered content\n",
    "        response_text += buffer\n",
    "        clear_output(wait=True)\n",
    "        display(Markdown(response_text))\n",
    "    else:\n",
    "        print(\"Request failed:\", response.status_code, response.text)\n",
    "\n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6c42d445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The Colombian conflict had approximately 0.45 million deaths."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = chat(\"How many death in Colombian conflict?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2cc31fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I don't know the specific references for this particular information on the Colombian conflict page. The sources listed in the provided context are:\n",
       "\n",
       "1. bercovitch, jacob jackson, richard (1997)\n",
       "2. congressional quarterly\n",
       "3. ictj.org (2009-01-01)\n",
       "4. marley, david (1998)\n",
       "5. abc-clio\n",
       "6. farcau, bruce w. (1996-05-23)\n",
       "7. bloomsbury academic\n",
       "8. portal guarani (in european spanish)\n",
       "9. tinker-salas, miguel (2015)\n",
       "10. oxford university press\n",
       "11. mwakikagile, godfrey (2014-04-21)\n",
       "12. new africa press\n",
       "13. arrian (1884)\n",
       "14. cornell university library\n",
       "15. london, hodder and stoughton\n",
       "16. arrian (2018-04-10)\n",
       "17. ozymandias press\n",
       "18. staff, historynet (2007-09-17)\n",
       "19. historynet\n",
       "20. herre, bastian rodés-guirao, lucas roser, max (2024-03-20)\n",
       "21. our world in data\n",
       "22. herre, bastian roser, max (2024-07-15)\n",
       "23. our world in data\n",
       "\n",
       "However, I couldn't find a single reference that directly cites the death toll of 0.45 million for the Colombian conflict."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = chat(\"Whats the reference of this information?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e47be809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Yes, you have been provided both the full URL and just the short version of it in the context."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = chat(\"You have been provided the source URL as well in the context. No?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e8ec84f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The source URL has indeed been provided in the context."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = chat(\"Thats the source I was asking for.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f9b4a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The source is https://en.wikipedia.org/wiki/List_of_wars_by_death_toll, retrieved on September 30, 2024."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = chat(\"Tell me whats the source?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
