{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc264dcf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "957660c2cd8946b6a1e740889547c877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing URLs:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 8\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "#from transformers import GPT2TokenizerFast\n",
    "from transformers import AutoTokenizer\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "#tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "\n",
    "model_path = '/Users/hissain/git/github/models/all-MiniLM-L6-v2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "def init_driver():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    service = Service()\n",
    "    return webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "def extract_text_from_url(url, driver):\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    soup = soup.body\n",
    "    if soup is None:\n",
    "        return \"\" \n",
    "    \n",
    "    for script in soup([\"script\", \"style\", \"footer\", \"header\", \"nav\", \"a\"]):\n",
    "        script.decompose()\n",
    "    \n",
    "    for element in soup.find_all(\"div\", class_=\"d-flex\"):\n",
    "        element.decompose()\n",
    "    \n",
    "    for hidden_elem in soup.find_all(lambda tag: tag.has_attr('hidden') or \n",
    "                                     (tag.has_attr('style') and ('display: none' in tag['style'] or 'visibility: hidden' in tag['style']))):\n",
    "        hidden_elem.decompose()\n",
    "        \n",
    "    text = soup.get_text(separator=\" \")\n",
    "    return text\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)           # Remove extra whitespace\n",
    "    text = re.sub(r'[^\\w\\s.,!?\\'\"()-]', '', text)  # Remove special characters\n",
    "    text = text.lower()                         # Normalize to lowercase\n",
    "    return text.strip()\n",
    "\n",
    "def split_sentences(text):\n",
    "    sentences = re.split(r'(?<=[.!?]) +', text)  # Split on sentence boundaries\n",
    "    return sentences\n",
    "\n",
    "def count_tokens(text):\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "def partition_sentences(sentences, url, max_tokens=512, overlap=1):\n",
    "    chunks, current_chunk = [], []\n",
    "    current_tokens = 0\n",
    "\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        sentence_tokens = count_tokens(sentence)\n",
    "        \n",
    "        if current_tokens + sentence_tokens > max_tokens:\n",
    "            chunks.append({\"text\": \" \".join(current_chunk), \"url\": url})\n",
    "            current_chunk = current_chunk[-overlap:]\n",
    "            current_tokens = count_tokens(\" \".join(current_chunk))\n",
    "\n",
    "        current_chunk.append(sentence)\n",
    "        current_tokens += sentence_tokens\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append({\"text\": \" \".join(current_chunk), \"url\": url})\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def process_urls(urls):\n",
    "    driver = init_driver()\n",
    "    all_chunks = []\n",
    "    \n",
    "    for url in tqdm(urls, desc=\"Processing URLs\"):\n",
    "        try:\n",
    "            raw_text = extract_text_from_url(url, driver)\n",
    "            clean_text_content = clean_text(raw_text)\n",
    "            sentences = split_sentences(clean_text_content)\n",
    "            chunks = partition_sentences(sentences, url, max_tokens=512, overlap=1)\n",
    "            all_chunks.extend(chunks)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {url}: {e}\")\n",
    "    \n",
    "    #driver.quit()\n",
    "    return all_chunks\n",
    "\n",
    "urls = [\n",
    "    \"https://github.com/hissain\",\n",
    "    \"https://github.com/hissain/CoronaTracker\",\n",
    "    \"https://github.com/hissain/minimal-cmsis-dsp\",\n",
    "    \"https://github.com/hissain/ml\"\n",
    "]\n",
    "\n",
    "rag_chunks = process_urls(urls)\n",
    "print(f\"Total chunks: {len(rag_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a071ac5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1:\n",
      "Text: hissain hissain block or report block or report hissain block user prevent this user from interacting with your repositories and sending you notifications. learn more about . you must be logged in to block users. add an optional note please don't include any personal information such as legal names or email addresses. maximum 100 characters, markdown supported. this note will be visible to only you. block user report abuse contact github support about this users behavior. learn more about . about me i am an accomplished associate architect with over 13 years of experience in mobile and wearables software development. with a deep understanding of the challenges inherent in developing performant, robust, testable, and maintainable applications, from requirement analysis to architecture, design, development, and maintenance, i am confident in my ability to lead software development and commercialization for any organization. my experience includes working on samsung health for ios, an application boasting over 6 million users and approximately 160k dau on the app store market, with a global rating of 4.5. between 2021 and 2024, i achieved six patent applications granted by samsung sipms, currently in the process of being published in uspto among them, one patent has already been published in uspto, wipo, and kr. my technical expertise encompasses oop, android (java, kotlin), ios (swift, objective-c), xcode, version control systems, system design, application architecture, development processes, wearable  hearable technology. additionally, i have experience in tizen app development and windows app development. currently, i am engaged in samsung earbuds device development on rtos, specifically in music streaming over bt classic and le audio, as well as in ballistocardiogram signal processing for stress score generation. my special interests include technological innovation, human-machine interaction, information theory, astronomy, probability, theory of relativity, philosophy of science, piano, guitar, and poetry. furthermore, i have pursued studies in critical thinking and how to make valid argumentation. i value the passion of problem-solving minds and firmly believe that software engineering is the profession that suits me best. i am always eager to learn and grow in my field and am committed to delivering high-quality solutions to my clients and stakeholders.\n",
      "URL: https://github.com/hissain\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, chunk in enumerate(rag_chunks[:1]):\n",
    "    print(f\"Chunk {i+1}:\\nText: {chunk['text']}\\nURL: {chunk['url']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c686a7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b28991a3a5344ab8d0c1f7781dcec74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 8 chunks\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from qdrant_client import QdrantClient, models\n",
    "from tqdm.notebook import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from IPython.display import display, clear_output, Markdown\n",
    "import requests\n",
    "import json\n",
    "import asyncio\n",
    "\n",
    "session = requests.Session()\n",
    "session.headers.update({\"Connection\": \"keep-alive\", \"Content-Type\": \"application/json\"})\n",
    "\n",
    "qdrant_url = \"http://localhost:6333\"\n",
    "collection_name = \"github_collection\"\n",
    "\n",
    "ollama_url_inf = \"http://localhost:11434/api/show\"\n",
    "ollama_url_emb = \"http://localhost:11434/api/embeddings\"\n",
    "ollama_url_gen = \"http://localhost:11434/api/generate\"\n",
    "ollama_model_name = \"llama3.2:latest\"\n",
    "\n",
    "client = QdrantClient(url=qdrant_url)\n",
    "embedding_model = SentenceTransformer(model_path)\n",
    "\n",
    "def get_embedding(text):\n",
    "    return embedding_model.encode(text)\n",
    "\n",
    "def create_collection(dimension):\n",
    "    try:\n",
    "        client.delete_collection(collection_name=collection_name)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=models.VectorParams(size=dimension, distance=models.Distance.COSINE),\n",
    "    )\n",
    "    \n",
    "def upsert_points_with_metadata(embeddings, chunks):\n",
    "    points = [\n",
    "        models.PointStruct(id=i, vector=embedding.tolist(), payload={\"text\": chunk[\"text\"], \"url\": chunk[\"url\"]})\n",
    "        for i, (embedding, chunk) in enumerate(zip(embeddings, chunks))\n",
    "    ]\n",
    "    client.upsert(collection_name=collection_name, points=points)\n",
    "\n",
    "def store_in_qdrant_with_metadata(chunks):\n",
    "    dimension = 384  # Dimension for 'all-MiniLM-L6-v2'\n",
    "    create_collection(dimension)\n",
    "    embeddings = [get_embedding(chunk[\"text\"]) for chunk in tqdm(chunks, desc=\"Generating embeddings\")]\n",
    "    upsert_points_with_metadata(embeddings, chunks)\n",
    "\n",
    "def search_points_with_metadata(query_embedding, k=3):\n",
    "    search_result = client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=query_embedding.tolist(),\n",
    "        limit=k,\n",
    "        with_payload=True\n",
    "    )\n",
    "    return [{\"text\": hit.payload[\"text\"], \"url\": hit.payload[\"url\"]} for hit in search_result]\n",
    "\n",
    "def ask(query, k=3, p=False):\n",
    "    \n",
    "    query_embedding = get_embedding(query)\n",
    "    retrieved_docs = search_points_with_metadata(query_embedding, k)\n",
    "    \n",
    "    combined_docs = \"\\n\\n\".join([f\"Source: {doc['url']}\\n{doc['text']}\" for doc in retrieved_docs])\n",
    "    inst = \"Instruction: If you do not find the answer in the context, just say you don't know.\"\n",
    "    rag_prompt = f\"{inst}\\n\\nContext:\\n{combined_docs}\\n\\nQuery: {query}\\nAnswer:\"\n",
    "    if p:\n",
    "        print(rag_prompt)\n",
    "        \n",
    "    payload = {\"model\": ollama_model_name, \"prompt\": rag_prompt, \"stream\": True}\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    response_text = \"\"\n",
    "    buffer = \"\"\n",
    "\n",
    "    response = session.post(ollama_url_gen, headers=headers, data=json.dumps(payload), stream=True)\n",
    "\n",
    "    # Process the response content as it arrives\n",
    "    if response.status_code == 200:\n",
    "        for chunk in response.iter_content(chunk_size=None):\n",
    "            try:\n",
    "                data = json.loads(chunk.decode('utf-8'))\n",
    "                content = data.get(\"response\", \"\")\n",
    "                buffer += content\n",
    "\n",
    "                # Display output every few characters for real-time effect\n",
    "                if len(buffer) > 10:\n",
    "                    response_text += buffer\n",
    "                    clear_output(wait=True)\n",
    "                    display(Markdown(response_text))\n",
    "                    buffer = \"\"\n",
    "                    \n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "\n",
    "        # Display any remaining buffered content\n",
    "        response_text += buffer\n",
    "        clear_output(wait=True)\n",
    "        display(Markdown(response_text))\n",
    "    else:\n",
    "        print(\"Request failed:\", response.status_code, response.text)\n",
    "\n",
    "    return response_text\n",
    "\n",
    "try:\n",
    "    store_in_qdrant_with_metadata(rag_chunks)\n",
    "    print(f'Stored {len(rag_chunks)} chunks')\n",
    "except Exception as e:\n",
    "    print(f\"Error storing in Qdrant: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32f89900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Technological innovation, human-machine interaction, information theory, astronomy, probability, theory of relativity, philosophy of science, piano, guitar, and poetry."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = ask(\"What are Hissain's special interests?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e4cae96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "CoronaTracker appears to be a project aimed at tracking COVID-19 cases, close contacts, and geographic locations of citizens. The app uses GPS, Bluetooth, and NFC data to detect close contacts for individuals who have tested positive for COVID-19, with the goal of identifying potential candidates for quarantine and further testing."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = ask(\"Tell me about CoronaTracker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bfd295d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Yes, there are several repositories available on GitHub for machine learning. One of them is the \"hissain/ml\" repository you mentioned earlier (https://github.com/hissain/ml), which contains a collection of basic and frequently used machine learning code snippets in various projects and tasks.\n",
       "\n",
       "Additionally, you can also explore other repositories such as:\n",
       "\n",
       "* https://github.com/hissain/minimal-cmsis-dsp (which includes some machine learning related files)\n",
       "* https://github.com/hissain (Hissain's GitHub profile page which has a list of his projects including one that might be related to machine learning)\n",
       "\n",
       "Please note that the first repository you mentioned is specifically focused on machine learning code snippets, and it's worth checking it out if you're looking for some inspiration or examples."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = ask(\"Any repository for Machine learning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9187c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_url_chat = \"http://localhost:11434/api/chat\"\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "def chat(query, k=2, p=False, stream=True):\n",
    "    global chat_history\n",
    "    \n",
    "    query_embedding = get_embedding(query)\n",
    "    retrieved_docs = search_points_with_metadata(query_embedding, k)\n",
    "    \n",
    "    combined_docs = \"\\n\\n\".join([f\"Source: {doc['url']}\\n{doc['text']}\" for doc in retrieved_docs])\n",
    "    inst = \"Instruction: If you do not find the answer in the context, just say you don't know.\"\n",
    "    rag_prompt = f\"{inst}\\n\\nContext:\\n{combined_docs}\\n\\nQuery: {query}\\nAnswer:\"\n",
    "    if p:\n",
    "        print(rag_prompt)\n",
    "        \n",
    "    chat_history.append({\"role\": \"user\", \"content\": rag_prompt})\n",
    "    payload = {\"model\": ollama_model_name, \"messages\": chat_history, \"stream\": stream}\n",
    "    headers = {\"Connection\": \"keep-alive\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "    response_text = \"\"\n",
    "    buffer = \"\"\n",
    "\n",
    "    response = session.post(ollama_url_chat, data=json.dumps(payload), stream=stream)\n",
    "\n",
    "    # Process the response content as it arrives\n",
    "    if response.status_code == 200:\n",
    "        for chunk in response.iter_content(chunk_size=None):\n",
    "            try:\n",
    "                data = json.loads(chunk.decode('utf-8'))\n",
    "                content = data.get(\"message\", {}).get(\"content\", \"\")\n",
    "                buffer += content\n",
    "\n",
    "                # Display output every few characters for real-time effect\n",
    "                if len(buffer) > 10:\n",
    "                    response_text += buffer\n",
    "                    clear_output(wait=True)\n",
    "                    display(Markdown(response_text))\n",
    "                    buffer = \"\"\n",
    "                    \n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "\n",
    "        # Display any remaining buffered content\n",
    "        response_text += buffer\n",
    "        clear_output(wait=True)\n",
    "        display(Markdown(response_text))\n",
    "    else:\n",
    "        print(\"Request failed:\", response.status_code, response.text)\n",
    "\n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "706a365f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hissain has over 13 years of experience in mobile and wearables software development. He has worked on Samsung Health for iOS, which boasts over 6 million users and approximately 160k downloads on the App Store market, with a global rating of 4.5. Additionally, he has achieved six patent applications granted by Samsung SIPMS between 2021 and 2024, currently in the process of being published in USPTO among them, one patent has already been published in USPTO, Wipo, and KR."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = chat(\"Whats Hissain experience?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54a69144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "1. Technological innovation\n",
       "2. Human-machine interaction\n",
       "3. Information theory\n",
       "4. Astronomy\n",
       "5. Probability\n",
       "6. Theory of relativity\n",
       "7. Philosophy of science\n",
       "8. Piano\n",
       "9. Guitar\n",
       "10. Poetry \n",
       "\n",
       "Additionally, his special interests are not limited to these areas, as he mentions that \"I value the passion of problem-solving minds and firmly believe that software engineering is the profession that suits me best.\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = chat(\"Whats his topic of special interest?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79f44e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This repository is licensed under the . feel free to use and modify the code as needed for your own projects."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = chat(\"Whats the license for https://github.com/hissain/ml repository?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
