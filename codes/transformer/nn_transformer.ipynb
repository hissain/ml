{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2e5ddc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from typing import Iterable, List\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from timeit import default_timer as timer\n",
    "from torch.nn import Transformer\n",
    "from torch import Tensor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0b94f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70c2de22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_seq_len,\n",
    "        num_encoder_layers: int,\n",
    "        num_decoder_layers: int,\n",
    "        emb_size: int,\n",
    "        nhead: int,\n",
    "        src_vocab_size: int,\n",
    "        tgt_vocab_size: int,\n",
    "        dim_feedforward: int,\n",
    "        dropout: float = 0.1\n",
    "    ):\n",
    "        super(Generator, self).__init__()\n",
    "        self.transformer = Transformer(\n",
    "            d_model=emb_size,\n",
    "            nhead=nhead,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = nn.Embedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = nn.Embedding(tgt_vocab_size, emb_size)\n",
    "        self.pos_emb = PositionalEncoding(emb_size, max_seq_len)\n",
    "\n",
    "    def forward(self,\n",
    "                src: Tensor,\n",
    "                trg: Tensor,\n",
    "                src_mask: Tensor,\n",
    "                tgt_mask: Tensor,\n",
    "                src_padding_mask: Tensor,\n",
    "                tgt_padding_mask: Tensor,\n",
    "                memory_key_padding_mask: Tensor):\n",
    "        \n",
    "        src_emb = self.pos_emb(self.src_tok_emb(src))\n",
    "        tgt_emb = self.pos_emb(self.tgt_tok_emb(trg))\n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
    "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer.encoder(self.pos_emb(self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer.decoder(self.pos_emb(self.tgt_tok_emb(tgt)), memory, tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dffe66a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158058\n",
      "17563\n",
      "(\"I'm not\", 'the problem.')\n",
      "('Do you', 'like to sing?')\n",
      "('She has shown', 'her room to me.')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "SRC_LANGUAGE = 'en'\n",
    "\n",
    "# Tokenizer\n",
    "token_transform = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "\n",
    "# Read dataset\n",
    "csv = pd.read_csv('~/datasets/en_fr/eng_-french.csv', usecols=['English words/sentences'])\n",
    "train_csv, test_csv = train_test_split(csv, test_size=0.1)\n",
    "\n",
    "print(len(train_csv))\n",
    "print(len(test_csv))\n",
    "\n",
    "# Custom Dataset class\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, csv):\n",
    "        self.csv = csv\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        s = self.csv.iloc[idx]['English words/sentences']\n",
    "        words = s.split()\n",
    "        midpoint = len(words) // 2\n",
    "        return ' '.join(words[:midpoint]), ' '.join(words[midpoint:])\n",
    "\n",
    "train_dataset = TranslationDataset(train_csv)\n",
    "valid_dataset = TranslationDataset(test_csv)\n",
    "\n",
    "# Iterate through dataset\n",
    "iterator = iter(train_dataset)\n",
    "print(next(iterator))\n",
    "print(next(iterator))\n",
    "print(next(iterator))\n",
    "\n",
    "# Helper function to yield list of tokens\n",
    "def yield_tokens(data_iter, language):\n",
    "    for data_sample in data_iter:\n",
    "        yield token_transform(data_sample[0])\n",
    "\n",
    "# Define special symbols and indices\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "\n",
    "# Build vocab\n",
    "vocab_transform = build_vocab_from_iterator(\n",
    "    yield_tokens(train_dataset, SRC_LANGUAGE),\n",
    "    min_freq=1,\n",
    "    specials=special_symbols,\n",
    "    special_first=True\n",
    ")\n",
    "vocab_transform.set_default_index(UNK_IDX)\n",
    "\n",
    "# Function to add BOS/EOS and create tensor for input sequence indices\n",
    "def tensor_transform(token_ids):\n",
    "    return torch.cat([torch.tensor([BOS_IDX]), torch.tensor(token_ids), torch.tensor([EOS_IDX])])\n",
    "\n",
    "# Text transformation function\n",
    "def text_transform(sentence):\n",
    "    return tensor_transform(vocab_transform(token_transform(sentence)))\n",
    "\n",
    "# Collate function for DataLoader\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_batch.append(text_transform(src_sample))\n",
    "        tgt_batch.append(text_transform(tgt_sample))\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX, batch_first=True)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX, batch_first=True)\n",
    "    return src_batch, tgt_batch\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec4f7a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (generator): Linear(in_features=192, out_features=9520, bias=True)\n",
       "  (src_tok_emb): Embedding(9520, 192)\n",
       "  (tgt_tok_emb): Embedding(9520, 192)\n",
       "  (pos_emb): PositionalEncoding()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SEQ_LEN = 64\n",
    "SRC_VOCAB_SIZE = len(vocab_transform)\n",
    "TGT_VOCAB_SIZE = len(vocab_transform)\n",
    "EMB_SIZE = 192\n",
    "NHEAD = 6\n",
    "FFN_HID_DIM = 192\n",
    "BATCH_SIZE = 256\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "DEVICE = 'cpu' #'cuda'\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "model = Generator(MAX_SEQ_LEN, NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE, NHEAD, \n",
    "                SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a4804fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea910dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[1]\n",
    "    tgt_seq_len = tgt.shape[1]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a73c44c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "def train_epoch(model, optimizer, loss_fn, device=DEVICE):\n",
    "    print('Training')\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for src, tgt in tqdm(train_dataloader):\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "        tgt_input = tgt[:, :-1]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        tgt_out = tgt[:, 1:]\n",
    "        loss = loss_fn(logits.view(-1, TGT_VOCAB_SIZE), tgt_out.contiguous().view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(train_dataloader)\n",
    "\n",
    "def evaluate(model, loss_fn, device=DEVICE):\n",
    "    print('Validating')\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in tqdm(val_dataloader):\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "            tgt_input = tgt[:, :-1]\n",
    "\n",
    "            src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "            logits = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "            tgt_out = tgt[:, 1:]\n",
    "            loss = loss_fn(logits.view(-1, TGT_VOCAB_SIZE), tgt_out.contiguous().view(-1))\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(val_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08d6e75d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2856039c566447778cf1feb3015b970f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/618 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93c82100e5c945c3b03d78c0f02cd176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 4.406, Val loss: 3.864, Epoch time = 585.367s \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss_list, valid_loss_list = [], []\n",
    "for epoch in range(1, 2):\n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch(model, optimizer, loss_fn, DEVICE)\n",
    "    valid_loss = evaluate(model, loss_fn, DEVICE)\n",
    "    end_time = timer()\n",
    "    train_loss_list.append(train_loss)\n",
    "    valid_loss_list.append(valid_loss)\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {valid_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s \\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "839f85df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.makedirs('outputs3', exist_ok=True)\n",
    "\n",
    "def save_plots(train_loss, valid_loss):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(\n",
    "        train_loss, color='blue', linestyle='-',\n",
    "        label='train loss'\n",
    "    )\n",
    "    plt.plot(\n",
    "        valid_loss, color='red', linestyle='-',\n",
    "        label='validataion loss'\n",
    "    )\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join('outputs3', 'loss.png'))\n",
    "    plt.show()\n",
    "    \n",
    "save_plots(train_loss_list, valid_loss_list)\n",
    "torch.save(model, 'outputs3/model.pth')\n",
    "model = torch.load('outputs3/model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "44823a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Take a look  saw at are .  \n",
      "Some \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Helper function to generate output sequence using specified decoding algorithm.\n",
    "def decode(model, src, src_mask, max_len, start_symbol, beam_size=3, stochastic=False, use_beam_search=False):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    sequences = [(torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE), 0)]  # (sequence, score)\n",
    "\n",
    "    for _ in range(max_len - 1):\n",
    "        all_candidates = []\n",
    "        for seq, score in sequences:\n",
    "            tgt_mask = (generate_square_subsequent_mask(seq.size(1)).type(torch.bool)).to(DEVICE)\n",
    "            out = model.decode(seq, memory, tgt_mask)\n",
    "            prob = model.generator(out[:, -1])\n",
    "            \n",
    "            if use_beam_search:\n",
    "                log_probs = F.log_softmax(prob, dim=1)\n",
    "                topk_probs, topk_indices = log_probs.topk(beam_size)\n",
    "\n",
    "                for i in range(beam_size):\n",
    "                    next_seq = torch.cat([seq, torch.ones(1, 1).type_as(src.data).fill_(topk_indices[0][i])], dim=1)\n",
    "                    next_score = score + topk_probs[0][i].item()\n",
    "                    all_candidates.append((next_seq, next_score))\n",
    "            else:\n",
    "                _, next_word = torch.max(prob, dim=1)\n",
    "                next_word = next_word.item()\n",
    "                next_seq = torch.cat([seq, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
    "                next_score = score\n",
    "                all_candidates.append((next_seq, next_score))\n",
    "                if next_word == EOS_IDX:\n",
    "                    return next_seq\n",
    "\n",
    "        if use_beam_search:\n",
    "            ordered = sorted(all_candidates, key=lambda x: x[1], reverse=True)\n",
    "            sequences = ordered[:beam_size]\n",
    "            if all(seq[0][-1].item() == EOS_IDX for seq, _ in sequences):\n",
    "                break\n",
    "\n",
    "    if use_beam_search:\n",
    "        if stochastic:\n",
    "            scores = [seq[1] for seq in sequences]\n",
    "            probabilities = F.softmax(torch.tensor(scores), dim=0).numpy()\n",
    "            chosen_index = np.random.choice(len(sequences), p=probabilities)\n",
    "            return sequences[chosen_index][0]\n",
    "        else:\n",
    "            return sequences[0][0]\n",
    "    else:\n",
    "        return sequences[0][0]\n",
    "\n",
    "# Translation function.\n",
    "def generate(model: torch.nn.Module, src_sentence: str, use_beam_search=False, stochastic=False):\n",
    "    model.eval()\n",
    "    src = text_transform(src_sentence).view(1, -1)\n",
    "    num_tokens = src.shape[1]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = decode(model, src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX, beam_size=3, stochastic=stochastic, use_beam_search=use_beam_search).flatten()\n",
    "    return src_sentence + \" \".join(vocab_transform.lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")\n",
    "\n",
    "# Example usage\n",
    "print(generate(model, \"Take a look \", use_beam_search=True, stochastic=True))\n",
    "print(generate(model, \"Some \", use_beam_search=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b1537c9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRC: Take a\n",
      "PRED: Take a here of whole . \n",
      "\n",
      "SRC: I'm not scared\n",
      "PRED: I'm not scared of my years . \n",
      "\n",
      "SRC: You'd better make\n",
      "PRED: You'd better make <unk> , do n't you problem  .  .\n",
      "\n",
      "SRC: The clock has\n",
      "PRED: The clock has a here of keep .  .  .\n",
      "\n",
      "SRC: Take any two cards\n",
      "PRED: Take any two cards 'd the <unk> of <unk> .   . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SRC, GT pairs from the validation set.\n",
    "infer_sentences = [\n",
    "    [\"Take a\"],\n",
    "    [\"I'm not scared\"],\n",
    "    [\"You'd better make\"],\n",
    "    [\"The clock has\"],\n",
    "    [\"Take any two cards\"]\n",
    "]\n",
    "\n",
    "for sentence in infer_sentences:\n",
    "    print(f\"SRC: {sentence[0]}\")\n",
    "    print(f\"PRED: {generate_beam(model, sentence[0], True)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a56cfabb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Move your See , makes .  . '"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_beam(model, \"Move your\", True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
