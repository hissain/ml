{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "0612e46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "\n",
    "class GridWorldEnv(gym.Env):\n",
    "    def __init__(self, n=5, start_pos=(0, 0), goal_pos=None, block_percentage=5):\n",
    "        super(GridWorldEnv, self).__init__()\n",
    "        \n",
    "        self.n = n\n",
    "        self.grid_size = (n, n)\n",
    "        \n",
    "        # Define the action space: 0 = left, 1 = right, 2 = up, 3 = down\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        \n",
    "        # Define the observation space, which is the position of the agent on the grid\n",
    "        self.observation_space = spaces.Tuple((\n",
    "            spaces.Discrete(n),\n",
    "            spaces.Discrete(n)\n",
    "        ))\n",
    "        \n",
    "        # Set the starting position of the agent\n",
    "        self.start_pos = start_pos\n",
    "        self.current_pos = self.start_pos\n",
    "        \n",
    "        # Set the goal position\n",
    "        self.goal_pos = goal_pos if goal_pos else (n-1, n-1)\n",
    "        \n",
    "        # Set the blocked cells, generate random blocked cells\n",
    "        num_cells = n * n\n",
    "        num_blocked = int((block_percentage / 100) * num_cells)\n",
    "        \n",
    "        self.blocked_cells = []\n",
    "        while len(self.blocked_cells) < num_blocked:\n",
    "            cell = (random.randint(0, n-1), random.randint(0, n-1))\n",
    "            if cell != self.start_pos and cell != self.goal_pos and cell not in self.blocked_cells:\n",
    "                self.blocked_cells.append(cell)\n",
    "        \n",
    "        # Create grid with obstacles\n",
    "        self.grid = np.zeros(self.grid_size)\n",
    "        for cell in self.blocked_cells:\n",
    "            self.grid[cell] = -1  # Mark blocked cells as -1\n",
    "        \n",
    "    def reset(self):\n",
    "        # Reset agent's position to start\n",
    "        self.current_pos = self.start_pos\n",
    "        return self.current_pos\n",
    "\n",
    "    def step(self, action):\n",
    "        x, y = self.current_pos\n",
    "\n",
    "        # Take action based on the agent's current position\n",
    "        if action == 0:  # Left\n",
    "            y = max(0, y - 1)\n",
    "        elif action == 1:  # Right\n",
    "            y = min(self.n - 1, y + 1)\n",
    "        elif action == 2:  # Up\n",
    "            x = max(0, x - 1)\n",
    "        elif action == 3:  # Down\n",
    "            x = min(self.n - 1, x + 1)\n",
    "        \n",
    "        next_pos = (x, y)\n",
    "\n",
    "        # Check if the next position is blocked\n",
    "        if next_pos in self.blocked_cells:\n",
    "            next_pos = self.current_pos  # Stay in the same position if blocked\n",
    "\n",
    "        # Set the new current position\n",
    "        self.current_pos = next_pos\n",
    "\n",
    "        # Check if the agent reached the goal\n",
    "        if self.current_pos == self.goal_pos:\n",
    "            reward = 10  # Reward for reaching the goal\n",
    "            done = True\n",
    "        else:\n",
    "            reward = -1  # Small penalty for each step taken\n",
    "            done = False\n",
    "\n",
    "        return self.current_pos, reward, done, {}\n",
    "\n",
    "    \n",
    "    def render(self, mode='human'):\n",
    "        grid = np.copy(self.grid)\n",
    "\n",
    "        # Mark the agent's position\n",
    "        grid[self.start_pos] = 3\n",
    "        \n",
    "        # Mark the agent's position\n",
    "        grid[self.current_pos] = 1\n",
    "\n",
    "        # Mark the goal position\n",
    "        grid[self.goal_pos] = 2\n",
    "\n",
    "        # Display the grid as an image\n",
    "        cmap = colors.ListedColormap(['black', 'white', 'red', 'yellow'])\n",
    "        bounds = [-1, 0, 1, 2, 3]\n",
    "        norm = colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(grid, cmap=cmap, norm=norm)\n",
    "\n",
    "        # Remove default grid lines and ticks\n",
    "        ax.set_xticks(np.arange(self.n) + 0.5, minor=True)\n",
    "        ax.set_yticks(np.arange(self.n) + 0.5, minor=True)\n",
    "        ax.grid(which=\"minor\", color=\"black\", linestyle='-', linewidth=1)  # Square boundaries\n",
    "\n",
    "        ax.set_xticks([])  # Remove tick marks\n",
    "        ax.set_yticks([])  # Remove tick marks\n",
    "\n",
    "        # Render agent, goal, and blocked cells in the center of the squares\n",
    "        for i in range(self.n):\n",
    "            for j in range(self.n):\n",
    "                if (i, j) == self.current_pos:\n",
    "                    ax.text(j, i, 'A', ha='center', va='center', fontsize=12, color='green')\n",
    "                elif (i, j) == self.start_pos:\n",
    "                    ax.text(j, i, 'S', ha='center', va='center', fontsize=12, color='green')  # Starting point\n",
    "                elif (i, j) == self.goal_pos:\n",
    "                    ax.text(j, i, 'G', ha='center', va='center', fontsize=12, color='red')\n",
    "                elif (i, j) in self.blocked_cells:\n",
    "                    ax.text(j, i, 'X', ha='center', va='center', fontsize=12, color='black')\n",
    "\n",
    "        plt.title(f\"Agent at {self.current_pos}, Goal at {self.goal_pos}\")\n",
    "        display(plt.gcf())\n",
    "        clear_output(wait=True)\n",
    "        time.sleep(0.3)\n",
    "        plt.close()\n",
    "\n",
    "    def show_final(self):\n",
    "        grid = np.copy(self.grid)\n",
    "\n",
    "        # Mark the agent's position\n",
    "        grid[self.start_pos] = 3\n",
    "        \n",
    "        # Mark the agent's position\n",
    "        grid[self.current_pos] = 1\n",
    "\n",
    "        # Mark the goal position\n",
    "        grid[self.goal_pos] = 2\n",
    "\n",
    "        # Display the grid as an image\n",
    "        cmap = colors.ListedColormap(['black', 'white', 'red', 'yellow'])\n",
    "        bounds = [-1, 0, 1, 2, 3]\n",
    "        norm = colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(grid, cmap=cmap, norm=norm)\n",
    "\n",
    "        # Remove default grid lines and ticks\n",
    "        ax.set_xticks(np.arange(self.n) + 0.5, minor=True)\n",
    "        ax.set_yticks(np.arange(self.n) + 0.5, minor=True)\n",
    "        ax.grid(which=\"minor\", color=\"black\", linestyle='-', linewidth=1)  # Square boundaries\n",
    "\n",
    "        ax.set_xticks([])  # Remove tick marks\n",
    "        ax.set_yticks([])  # Remove tick marks\n",
    "\n",
    "        # Render agent, goal, and blocked cells in the center of the squares\n",
    "        for i in range(self.n):\n",
    "            for j in range(self.n):\n",
    "                if (i, j) == self.current_pos:\n",
    "                    ax.text(j, i, 'A', ha='center', va='center', fontsize=12, color='green')\n",
    "                elif (i, j) == self.start_pos:\n",
    "                    ax.text(j, i, 'S', ha='center', va='center', fontsize=12, color='green')  # Starting point\n",
    "                elif (i, j) == self.goal_pos:\n",
    "                    ax.text(j, i, 'G', ha='center', va='center', fontsize=12, color='red')\n",
    "                elif (i, j) in self.blocked_cells:\n",
    "                    ax.text(j, i, 'X', ha='center', va='center', fontsize=12, color='black')\n",
    "\n",
    "        plt.title(f\"Agent at {self.current_pos}, Goal at {self.goal_pos}\")\n",
    "        plt.show()\n",
    "\n",
    "# Define policy\n",
    "def run_policy(env, q_table):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    env.render()\n",
    "    while not done:\n",
    "        action = np.argmax(q_table[state[0], state[1]])\n",
    "        state, _, done, _ = env.step(action)\n",
    "        env.render()\n",
    "    env.show_final()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "bc3be942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100, Total Reward: -8, Epsilon: 0.6057704364907278\n",
      "Episode 200, Total Reward: -5, Epsilon: 0.3669578217261671\n",
      "Episode 300, Total Reward: -1, Epsilon: 0.22229219984074702\n",
      "Episode 400, Total Reward: 0, Epsilon: 0.1346580429260134\n",
      "Episode 500, Total Reward: 0, Epsilon: 0.1\n",
      "Episode 600, Total Reward: 0, Epsilon: 0.1\n",
      "Episode 700, Total Reward: -1, Epsilon: 0.1\n",
      "Episode 800, Total Reward: 0, Epsilon: 0.1\n",
      "Episode 900, Total Reward: 1, Epsilon: 0.1\n",
      "Episode 1000, Total Reward: -1, Epsilon: 0.1\n",
      "Training finished!\n"
     ]
    }
   ],
   "source": [
    "# Define grid size and blocked cells percentage\n",
    "n = 6\n",
    "start_pos = (0, 0)\n",
    "goal_pos = (n-1, n-1)\n",
    "block_percentage = 20\n",
    "\n",
    "env = GridWorldEnv(n=n, start_pos=start_pos, goal_pos=goal_pos, block_percentage=block_percentage)\n",
    "\n",
    "# Q-learning parameters\n",
    "q_table = np.zeros((n, n, env.action_space.n))\n",
    "alpha = 0.1  # Learning rate\n",
    "gamma = 0.99  # Discount factor\n",
    "epsilon = 1.0  # Exploration rate\n",
    "epsilon_min = 0.1\n",
    "epsilon_decay = 0.995\n",
    "num_episodes = 1000\n",
    "max_steps = 500\n",
    "\n",
    "# Q-learning algorithm\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    \n",
    "    for step in range(max_steps):\n",
    "        if random.uniform(0, 1) < epsilon:\n",
    "            action = env.action_space.sample()  # Explore action space\n",
    "        else:\n",
    "            action = np.argmax(q_table[state[0], state[1]])  # Exploit learned values\n",
    "        \n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        # Update Q-value\n",
    "        q_table[state[0], state[1], action] = q_table[state[0], state[1], action] + alpha * (\n",
    "            reward + gamma * np.max(q_table[next_state[0], next_state[1]]) - q_table[state[0], state[1], action]\n",
    "        )\n",
    "        \n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    # Decay epsilon\n",
    "    epsilon = max(epsilon_min, epsilon_decay * epsilon)\n",
    "\n",
    "    if (episode + 1) % 100 == 0:\n",
    "        print(f\"Episode {episode + 1}, Total Reward: {total_reward}, Epsilon: {epsilon}\")\n",
    "\n",
    "print(\"Training finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "964504fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the trained agent\n",
    "run_policy(env, q_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
