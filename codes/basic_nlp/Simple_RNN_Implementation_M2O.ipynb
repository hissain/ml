{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hissain/mlworks/blob/main/codes/Simple_RNN_Implementation_M2O.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdowMQHxCnue"
      },
      "outputs": [],
      "source": [
        "# Import\n",
        "%matplotlib inline\n",
        "import math\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Zsdrcn1Jbyv",
        "outputId": "5cbb0896-1f2b-45e6-b578-c468516c6b14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7dd5243219f0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNLayer(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(RNNLayer, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # Weight matrices for input and hidden layer connections\n",
        "        self.W_xh = torch.nn.Parameter(torch.randn(input_size, hidden_size))\n",
        "        self.W_hh = torch.nn.Parameter(torch.randn(hidden_size, hidden_size))\n",
        "        # Bias term for hidden layer\n",
        "        self.b_h = torch.nn.Parameter(torch.zeros(hidden_size))\n",
        "\n",
        "    def forward(self, input_data, hidden_state=None):\n",
        "        \"\"\"\n",
        "        Performs a forward pass through the RNN layer.\n",
        "\n",
        "        Args:\n",
        "            input_data: A tensor of shape (batch_size, seq_len, input_size) representing the input sequence.\n",
        "            hidden_state: A tensor of shape (batch_size, hidden_size) representing the initial hidden state (optional).\n",
        "\n",
        "        Returns:\n",
        "            prediction: A tensor of shape (batch_size, output_size) representing the prediction from this model.\n",
        "            hidden_state: A tensor of shape (batch_size, hidden_size) representing the final hidden state.\n",
        "        \"\"\"\n",
        "        batch_size, seq_len, _ = input_data.size()\n",
        "\n",
        "        # Initialize hidden state if not provided\n",
        "        if hidden_state is None:\n",
        "            hidden_state = torch.zeros(batch_size, self.hidden_size)\n",
        "\n",
        "        # Loop through the sequence\n",
        "        for t in range(seq_len):\n",
        "            # Calculate current hidden state\n",
        "            hidden_state = torch.tanh(\n",
        "                # (batch_size, input_size) x (input_size, hidden_size)\n",
        "                # = (batch_size, hidden_size)\n",
        "                torch.mm(input_data[:, t, :], self.W_xh) + \\\n",
        "                # (batch_size, hidden_size) x (hidden_size, hidden_size)\n",
        "                # = (batch_size, hidden_size)\n",
        "                torch.mm(hidden_state, self.W_hh) + \\\n",
        "                # hidden_size\n",
        "                self.b_h\n",
        "            )\n",
        "\n",
        "        return hidden_state\n"
      ],
      "metadata": {
        "id": "hGC_9V-bFbVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNModel(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.rnn = RNNLayer(input_size, hidden_size)\n",
        "        self.fc = torch.nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"\n",
        "        Performs a forward pass through the RNN model.\n",
        "\n",
        "        Args:\n",
        "            inputs: A tensor of shape (batch_size, seq_len, input_size) representing the input sequence.\n",
        "\n",
        "        Returns:\n",
        "            prediction: A tensor of shape (batch_size, seq_len, output_size) representing the model output at each time step.\n",
        "        \"\"\"\n",
        "        # Pass data through RNN layer\n",
        "        hidden_state = self.rnn(inputs)\n",
        "\n",
        "        # Apply final linear layer\n",
        "        prediction = self.fc(hidden_state)\n",
        "\n",
        "        return prediction\n"
      ],
      "metadata": {
        "id": "U7vyplK4dQaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameters\n",
        "input_size =  3  # Vocabulary size (assuming one-hot encoded words)\n",
        "hidden_size = 20\n",
        "output_size = 3"
      ],
      "metadata": {
        "id": "S_gMfgPjreyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model instance\n",
        "model = RNNModel(input_size, hidden_size, output_size)"
      ],
      "metadata": {
        "id": "vKGUHryHrfu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example input sequence (one-hot encoded)\n",
        "inputs = torch.tensor([\n",
        "    [[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0]],\n",
        "    [[0, 1, 0], [1, 0, 0], [0, 0, 1], [1, 0, 0]]\n",
        "    ], dtype=torch.float\n",
        ")\n",
        "print(inputs.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AH0H3KurgvU",
        "outputId": "db44ce63-0b6c-4acc-bed2-26ff9d867cb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 4, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = torch.tensor([1, 2], dtype=torch.int64)"
      ],
      "metadata": {
        "id": "jAG8dXlpryD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass the sequence through the model\n",
        "with torch.no_grad():\n",
        "    predictions = model(inputs)\n",
        "    print(predictions.size())\n",
        "    predictions = torch.argmax(predictions, dim=1)\n",
        "    print(predictions.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PY-PNFlQriC8",
        "outputId": "93b8975b-cca8-4ae9-aebd-256adf60a2a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3])\n",
            "torch.Size([2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.tolist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B99rzRYcJNub",
        "outputId": "5c0bd956-0e8e-4dfe-c092-24ac86741a20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.tolist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivguiA8fsuLL",
        "outputId": "3a8a80f7-6b16-4f6b-e87e-62bef0f3d4f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy before training\n",
        "acc = (torch.sum(predictions == outputs) / predictions.numel()).item()\n",
        "print(f\"Accuracy: \", acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i46LjJMYnZI3",
        "outputId": "e8bb573f-4311-4a3d-c8ad-7c82e137fb10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameters\n",
        "learning_rate = 0.001\n",
        "num_epochs = 50"
      ],
      "metadata": {
        "id": "1ftuzhAR5OFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "Tv1Inf-j5-wQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for i in range(len(inputs)):\n",
        "        input, output = inputs[i:i+1], outputs[i:i+1]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        prediction = model(input)\n",
        "\n",
        "        loss = criterion(\n",
        "            prediction.float(),\n",
        "            F.one_hot(output, num_classes=3).float()\n",
        "        )\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss}\")"
      ],
      "metadata": {
        "id": "mLF2-kKs5IBV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6931a89f-7b48-4322-94ba-9f692ff1bdb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.8650309443473816\n",
            "Epoch 2, Loss: 1.7577070593833923\n",
            "Epoch 3, Loss: 1.6827844977378845\n",
            "Epoch 4, Loss: 1.6224281787872314\n",
            "Epoch 5, Loss: 1.569210708141327\n",
            "Epoch 6, Loss: 1.5195696949958801\n",
            "Epoch 7, Loss: 1.4719154834747314\n",
            "Epoch 8, Loss: 1.4255220293998718\n",
            "Epoch 9, Loss: 1.380059391260147\n",
            "Epoch 10, Loss: 1.3353986144065857\n",
            "Epoch 11, Loss: 1.2915146052837372\n",
            "Epoch 12, Loss: 1.248432219028473\n",
            "Epoch 13, Loss: 1.2061977088451385\n",
            "Epoch 14, Loss: 1.1648686528205872\n",
            "Epoch 15, Loss: 1.1245061755180359\n",
            "Epoch 16, Loss: 1.0851654708385468\n",
            "Epoch 17, Loss: 1.0468702912330627\n",
            "Epoch 18, Loss: 1.0095640420913696\n",
            "Epoch 19, Loss: 0.973041832447052\n",
            "Epoch 20, Loss: 0.9369140565395355\n",
            "Epoch 21, Loss: 0.9006874263286591\n",
            "Epoch 22, Loss: 0.8640312254428864\n",
            "Epoch 23, Loss: 0.8271685838699341\n",
            "Epoch 24, Loss: 0.7911084294319153\n",
            "Epoch 25, Loss: 0.7572945356369019\n",
            "Epoch 26, Loss: 0.7266700863838196\n",
            "Epoch 27, Loss: 0.699016660451889\n",
            "Epoch 28, Loss: 0.6733288466930389\n",
            "Epoch 29, Loss: 0.6487050354480743\n",
            "Epoch 30, Loss: 0.6246893554925919\n",
            "Epoch 31, Loss: 0.6010193228721619\n",
            "Epoch 32, Loss: 0.577241912484169\n",
            "Epoch 33, Loss: 0.5524295419454575\n",
            "Epoch 34, Loss: 0.5252409875392914\n",
            "Epoch 35, Loss: 0.49532119929790497\n",
            "Epoch 36, Loss: 0.46617570519447327\n",
            "Epoch 37, Loss: 0.4428974539041519\n",
            "Epoch 38, Loss: 0.42562946677207947\n",
            "Epoch 39, Loss: 0.41137923300266266\n",
            "Epoch 40, Loss: 0.3979424834251404\n",
            "Epoch 41, Loss: 0.38451647758483887\n",
            "Epoch 42, Loss: 0.3711439073085785\n",
            "Epoch 43, Loss: 0.3581588864326477\n",
            "Epoch 44, Loss: 0.34586167335510254\n",
            "Epoch 45, Loss: 0.334414079785347\n",
            "Epoch 46, Loss: 0.3238527327775955\n",
            "Epoch 47, Loss: 0.3141344040632248\n",
            "Epoch 48, Loss: 0.3051783889532089\n",
            "Epoch 49, Loss: 0.2968922257423401\n",
            "Epoch 50, Loss: 0.28918857872486115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass the sequence through the model\n",
        "with torch.no_grad():\n",
        "    predictions = model(inputs)\n",
        "    print(predictions.size())\n",
        "    predictions = torch.argmax(predictions, dim=1)\n",
        "    print(predictions.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gvby4x16NohT",
        "outputId": "d1a9793b-9068-4a95-cc33-0a7c4072bf99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3])\n",
            "torch.Size([2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.tolist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLWUtfGwNy3a",
        "outputId": "625679e9-6658-4379-9a98-7bde236e7d2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy after training\n",
        "acc = (torch.sum(predictions == outputs) / predictions.numel()).item()\n",
        "print(f\"Accuracy: \", acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJaZixTdNlVE",
        "outputId": "c02bc0f6-99f9-4fa2-d9a2-d28f54e4011e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6DdibXzdN4-_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}