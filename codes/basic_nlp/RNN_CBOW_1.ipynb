{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hissain/mlworks/blob/main/codes/RNN_CBOW_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "kH3NgfTuJJXL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ydRlAUfNJYAm"
      },
      "outputs": [],
      "source": [
        "# Constant definition\n",
        "RANDOM_SEED = 1\n",
        "CONTEXT_SIZE = 3\n",
        "EMBEDDING_DIM = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPHTsGZiVE5y",
        "outputId": "c42d9d0f-8d7d-4b19-d6dd-cedfdcd35fb0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x118e5d990>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "KixNPnOqJs4K"
      },
      "outputs": [],
      "source": [
        "# word level tokenization\n",
        "class Tokenizer:\n",
        "    def __init__(self):\n",
        "        self.mapping = {}\n",
        "        self.reverse_mapping = {}\n",
        "\n",
        "    def encode(self, text):\n",
        "        words = text.split()\n",
        "        tokens = []\n",
        "        for word in words:\n",
        "            if word not in self.mapping:\n",
        "                mapped_int = len(self.mapping)\n",
        "                self.mapping[word] = mapped_int\n",
        "                self.reverse_mapping[mapped_int] = word\n",
        "            tokens.append(self.mapping[word])\n",
        "        return tokens\n",
        "\n",
        "    def decode(self, tokens):\n",
        "        words = [self.reverse_mapping[token] for token in tokens]\n",
        "        return \" \".join(words)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "rDEtkR14g7Fn"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "mV-GVqEohGcb"
      },
      "outputs": [],
      "source": [
        "# Taking a random paragraph\n",
        "text = \"We are living in an AI era . One day AI will take all the Human jobs .\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "4Y4vNjoGJvX4"
      },
      "outputs": [],
      "source": [
        "# Generating dataset\n",
        "dataset = []\n",
        "tokens = tokenizer.encode(text)\n",
        "for i in range(len(tokens) - CONTEXT_SIZE):\n",
        "    dataset.append((tokens[i:i + CONTEXT_SIZE], tokens[i + CONTEXT_SIZE]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpXbcKGPg9ch",
        "outputId": "a57cc651-50c8-446b-cc24-ab975041c6d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16\n"
          ]
        }
      ],
      "source": [
        "vocab_size = len(tokenizer.mapping)\n",
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "FOTiazubYQXq"
      },
      "outputs": [],
      "source": [
        "# Used for tokenization purpose\n",
        "def get_one_hot(tokens):\n",
        "    return F.one_hot(\n",
        "        torch.tensor(tokens),\n",
        "        num_classes=vocab_size\n",
        "    ).flatten().type(torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "cGjResgcYqKh"
      },
      "outputs": [],
      "source": [
        "# Define the CBOW model\n",
        "class CBOW(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, context_size):\n",
        "    super(CBOW, self).__init__()\n",
        "    self.hidden = nn.Linear(vocab_size * context_size, embedding_dim)\n",
        "    self.output = nn.Linear(embedding_dim, vocab_size)\n",
        "\n",
        "  def forward(self, input):\n",
        "    return self.output(self.hidden(get_one_hot(input)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "QLNEtvRZYr2z"
      },
      "outputs": [],
      "source": [
        "# Create the model\n",
        "model = CBOW(vocab_size, EMBEDDING_DIM, CONTEXT_SIZE)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rb79f-I4-ZJ1",
        "outputId": "d3a27311-296a-4193-95bc-6bf8db03a527"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRpSJfJTYtMc",
        "outputId": "733afb0e-e335-4aab-badc-14fc9f9f9819"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "41.66307067871094\n",
            "41.2083854675293\n",
            "40.83362579345703\n",
            "40.462249755859375\n",
            "40.088836669921875\n",
            "39.71091842651367\n",
            "39.32661056518555\n",
            "38.934146881103516\n",
            "38.53190612792969\n",
            "38.1184196472168\n",
            "37.69240951538086\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "37.252830505371094\n",
            "36.798851013183594\n",
            "36.329830169677734\n",
            "35.84531784057617\n",
            "35.34503936767578\n",
            "34.82884216308594\n",
            "34.2967529296875\n",
            "33.748931884765625\n",
            "33.18568420410156\n",
            "32.60744094848633\n",
            "32.0147590637207\n",
            "31.408281326293945\n",
            "30.788738250732422\n",
            "30.15692710876465\n",
            "29.513708114624023\n",
            "28.859996795654297\n",
            "28.19676971435547\n",
            "27.525053024291992\n",
            "26.845914840698242\n",
            "26.16048812866211\n",
            "25.4699649810791\n",
            "24.775577545166016\n",
            "24.07860565185547\n",
            "23.380393981933594\n",
            "22.68229866027832\n",
            "21.985736846923828\n",
            "21.2921085357666\n",
            "20.602827072143555\n",
            "19.9193058013916\n",
            "19.242897033691406\n",
            "18.574926376342773\n",
            "17.916641235351562\n",
            "17.26921844482422\n",
            "16.633743286132812\n",
            "16.011194229125977\n",
            "15.40245246887207\n",
            "14.808279991149902\n",
            "14.229337692260742\n",
            "13.666165351867676\n",
            "13.119205474853516\n",
            "12.588802337646484\n",
            "12.07519817352295\n",
            "11.57855224609375\n",
            "11.098942756652832\n",
            "10.636371612548828\n",
            "10.190774917602539\n",
            "9.7620267868042\n",
            "9.349943161010742\n",
            "8.95429515838623\n",
            "8.57480239868164\n",
            "8.21114444732666\n",
            "7.862966537475586\n",
            "7.529881954193115\n",
            "7.211475372314453\n",
            "6.907311916351318\n",
            "6.616932392120361\n",
            "6.33986759185791\n",
            "6.075638771057129\n",
            "5.823759078979492\n",
            "5.583737850189209\n",
            "5.355086803436279\n",
            "5.137320041656494\n",
            "4.929956912994385\n",
            "4.732528209686279\n",
            "4.544571876525879\n",
            "4.365639686584473\n",
            "4.195294380187988\n",
            "4.033115863800049\n",
            "3.8786964416503906\n",
            "3.7316462993621826\n",
            "3.5915913581848145\n",
            "3.4581716060638428\n",
            "3.331045150756836\n",
            "3.2098848819732666\n",
            "3.0943801403045654\n",
            "2.9842348098754883\n",
            "2.879168748855591\n",
            "2.778913736343384\n",
            "2.6832196712493896\n",
            "2.591845750808716\n",
            "2.504565477371216\n",
            "2.42116641998291\n",
            "2.341444253921509\n",
            "2.2652087211608887\n",
            "2.1922788619995117\n",
            "2.1224851608276367\n",
            "2.055663824081421\n",
            "1.9916656017303467\n",
            "1.9303468465805054\n"
          ]
        }
      ],
      "source": [
        "# Training\n",
        "for epoch in range(100):\n",
        "    total_loss = 0\n",
        "    for input, label in dataset:\n",
        "        predictions = model(input)\n",
        "        loss = loss_function(predictions, get_one_hot(label))\n",
        "        total_loss += loss\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(total_loss.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zy3ZKHI5JhMI",
        "outputId": "add9d564-eeb2-449f-d0d3-7f7e2624329c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10\n",
            "will\n"
          ]
        }
      ],
      "source": [
        "# Testing\n",
        "input_text = \"One day AI\"\n",
        "correct_output = \"will\"\n",
        "\n",
        "with torch.no_grad():\n",
        "    prediction = model(tokenizer.encode(input_text))\n",
        "    print(torch.argmax(prediction).item())\n",
        "    print(tokenizer.reverse_mapping[torch.argmax(prediction).item()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TI9fW5PadvqQ",
        "outputId": "93f773da-b99f-4773-fc79-f9e757d40af2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-0.6185,  0.7577,  0.4743,  0.5531, -0.6016,  0.5008,  0.0481, -0.6179,\n",
            "         0.3598,  0.2874], grad_fn=<SelectBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Embedding of a word\n",
        "token = tokenizer.mapping[\"will\"]\n",
        "print(model.output.weight[token])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdqcKIMaZy7g"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
