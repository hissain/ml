{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hissain/mlworks/blob/main/codes/RNN_CBOW_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install torchtext torchdata portalocker>=2.0.0"
      ],
      "metadata": {
        "id": "H-Wzctmpfg0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "kH3NgfTuJJXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Constant definition\n",
        "RANDOM_SEED = 1\n",
        "CONTEXT_SIZE = 3\n",
        "EMBEDDING_DIM = 10"
      ],
      "metadata": {
        "id": "ydRlAUfNJYAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(RANDOM_SEED)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPHTsGZiVE5y",
        "outputId": "c29cae6d-bd21-4c0c-a708-b2e63c10e66e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fe5041e2790>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# word level tokenization\n",
        "class Tokenizer:\n",
        "    def __init__(self):\n",
        "        self.mapping = {}\n",
        "        self.reverse_mapping = {}\n",
        "\n",
        "    def encode(self, text):\n",
        "        words = text.split()\n",
        "        tokens = []\n",
        "        for word in words:\n",
        "            if word not in self.mapping:\n",
        "                mapped_int = len(self.mapping)\n",
        "                self.mapping[word] = mapped_int\n",
        "                self.reverse_mapping[mapped_int] = word\n",
        "            tokens.append(self.mapping[word])\n",
        "        return tokens\n",
        "\n",
        "    def decode(self, tokens):\n",
        "        words = [self.reverse_mapping[token] for token in tokens]\n",
        "        return \" \".join(words)\n"
      ],
      "metadata": {
        "id": "KixNPnOqJs4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()"
      ],
      "metadata": {
        "id": "rDEtkR14g7Fn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading IMDB dataset\n",
        "# Source: http://ai.stanford.edu/~amaas/data/sentiment/\n",
        "from torchtext.datasets import IMDB\n",
        "train_iter = IMDB(split='train')"
      ],
      "metadata": {
        "id": "mV-GVqEohGcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating dataset\n",
        "dataset = []\n",
        "# Converting all to tokens\n",
        "for label, line in train_iter:\n",
        "    tokens = tokenizer.encode(line)\n",
        "    for i in range(len(tokens) - CONTEXT_SIZE):\n",
        "        dataset.append((tokens[i:i + CONTEXT_SIZE], tokens[i + CONTEXT_SIZE]))"
      ],
      "metadata": {
        "id": "4Y4vNjoGJvX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.mapping)\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpXbcKGPg9ch",
        "outputId": "24ebe522-aa80-41f1-8513-700603ca8fd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "280617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Used for tokenization purpose\n",
        "def get_one_hot(tokens):\n",
        "    return F.one_hot(\n",
        "        torch.tensor(tokens),\n",
        "        num_classes=vocab_size\n",
        "    ).flatten().type(torch.float).to('cuda')"
      ],
      "metadata": {
        "id": "FOTiazubYQXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CBOW model\n",
        "class CBOW(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, context_size):\n",
        "    super(CBOW, self).__init__()\n",
        "    self.hidden = nn.Linear(vocab_size * context_size, embedding_dim, device=\"cuda\")\n",
        "    self.output = nn.Linear(embedding_dim, vocab_size, device=\"cuda\")\n",
        "\n",
        "  def forward(self, input):\n",
        "    return self.output(self.hidden(get_one_hot(input)))"
      ],
      "metadata": {
        "id": "cGjResgcYqKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "model = CBOW(vocab_size, EMBEDDING_DIM, CONTEXT_SIZE)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "QLNEtvRZYr2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64e11d7VzJeg",
        "outputId": "8b76c49f-448a-484f-b47d-aecff37dbf06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5769680"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "for epoch in range(100):\n",
        "    total_loss = 0\n",
        "    for input, label in dataset[:100]:\n",
        "        predictions = model(input)\n",
        "        loss = loss_function(predictions, get_one_hot(label))\n",
        "        total_loss += loss\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # print(loss.item())\n",
        "    print(total_loss.item())"
      ],
      "metadata": {
        "id": "sRpSJfJTYtMc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1e11384-b1b9-4c3f-d946-0ae5446fac60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "638.3038330078125\n",
            "579.9682006835938\n",
            "557.775146484375\n",
            "542.259765625\n",
            "528.4616088867188\n",
            "515.0277709960938\n",
            "501.28912353515625\n",
            "486.8854675292969\n",
            "471.597900390625\n",
            "455.286376953125\n",
            "437.9103698730469\n",
            "419.5715637207031\n",
            "400.56365966796875\n",
            "381.3873291015625\n",
            "362.6524963378906\n",
            "344.8702087402344\n",
            "328.2801208496094\n",
            "312.8523254394531\n",
            "298.4093017578125\n",
            "284.74456787109375\n",
            "271.68359375\n",
            "259.10125732421875\n",
            "246.91754150390625\n",
            "235.08901977539062\n",
            "223.59815979003906\n",
            "212.444580078125\n",
            "201.63699340820312\n",
            "191.1876220703125\n",
            "181.10838317871094\n",
            "171.40745544433594\n",
            "162.08926391601562\n",
            "153.1543426513672\n",
            "144.5998992919922\n",
            "136.4208526611328\n",
            "128.6103515625\n",
            "121.16064453125\n",
            "114.06331634521484\n",
            "107.30990600585938\n",
            "100.89163208007812\n",
            "94.79962158203125\n",
            "89.02440643310547\n",
            "83.55644226074219\n",
            "78.3853530883789\n",
            "73.50056457519531\n",
            "68.89105987548828\n",
            "64.54551696777344\n",
            "60.452491760253906\n",
            "56.600494384765625\n",
            "52.97810363769531\n",
            "49.5739860534668\n",
            "46.37704849243164\n",
            "43.37643814086914\n",
            "40.56161117553711\n",
            "37.922279357910156\n",
            "35.44866943359375\n",
            "33.13129425048828\n",
            "30.961183547973633\n",
            "28.92974853515625\n",
            "27.02889633178711\n",
            "25.250953674316406\n",
            "23.58867835998535\n",
            "22.035276412963867\n",
            "20.58433723449707\n",
            "19.229835510253906\n",
            "17.966066360473633\n",
            "16.78767967224121\n",
            "15.689563751220703\n",
            "14.666848182678223\n",
            "13.714821815490723\n",
            "12.828996658325195\n",
            "12.005000114440918\n",
            "11.23864459991455\n",
            "10.525928497314453\n",
            "9.862997055053711\n",
            "9.246240615844727\n",
            "8.67223072052002\n",
            "8.137777328491211\n",
            "7.639917850494385\n",
            "7.175878047943115\n",
            "6.743107318878174\n",
            "6.339261531829834\n",
            "5.962173938751221\n",
            "5.609863758087158\n",
            "5.280488014221191\n",
            "4.972378253936768\n",
            "4.683982849121094\n",
            "4.413893699645996\n",
            "4.160806179046631\n",
            "3.923515558242798\n",
            "3.700921058654785\n",
            "3.4920082092285156\n",
            "3.2958407402038574\n",
            "3.1115517616271973\n",
            "2.938343048095703\n",
            "2.775477886199951\n",
            "2.622276782989502\n",
            "2.478102684020996\n",
            "2.342372179031372\n",
            "2.214545488357544\n",
            "2.0941147804260254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "with torch.no_grad():\n",
        "    input_text = \"movie was good\"\n",
        "    for i in range(5):\n",
        "        prediction = model(tokenizer.encode(input_text))\n",
        "        # print(torch.argmax(prediction).item())\n",
        "        print(input_text, tokenizer.reverse_mapping[torch.argmax(prediction).item()])\n",
        "        input_text = input_text[input_text.index(\" \") + 1:] + \" \" + tokenizer.reverse_mapping[torch.argmax(prediction).item()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zy3ZKHI5JhMI",
        "outputId": "0f61d970-2d24-4e5e-d4d0-12f300e27719"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "movie was good released\n",
            "was good released in\n",
            "good released in 1967.\n",
            "released in 1967. I\n",
            "in 1967. I also\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding of a word\n",
        "token = tokenizer.mapping[\"movie\"]\n",
        "print(model.output.weight[token])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TI9fW5PadvqQ",
        "outputId": "766ac9ce-a53a-4bcb-8698-4a3e763a0a82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.3852, -2.0231, -0.8462, -0.8344,  1.2325,  1.1313, -0.8794, -0.9071,\n",
            "         0.1915,  0.6741], device='cuda:0', grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cdqcKIMaZy7g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}